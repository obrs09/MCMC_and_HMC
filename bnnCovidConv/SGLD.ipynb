{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7621e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd884f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndim\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import argparse\n",
    "import matplotlib\n",
    "from src.Stochastic_Gradient_Langevin_Dynamics.model import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import collections\n",
    "import h5py, sys\n",
    "import gzip\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4853ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_resize_size = 256\n",
    "image_trans_size = 224\n",
    "prior_sig = 0.1\n",
    "batch_size = 20\n",
    "nb_epochs = 100\n",
    "models_dir =  'models_SGLD_COVID150'\n",
    "# Where to save plots and error, accuracy vectors\n",
    "results_dir =  'results_SGLD_COVID150'\n",
    "\n",
    "use_preconditioning = False\n",
    "lr = 0.0000001\n",
    "\n",
    "\n",
    "\n",
    "save_data = True\n",
    "n_samples = batch_size\n",
    "sample_freq = 2\n",
    "burn_in = 20\n",
    "Nsamples = n_samples\n",
    "save_every = int(nb_epochs/20)  \n",
    "# We sample every 2 epochs as I have found samples to be correlated after only 1\n",
    "num_workers = 4\n",
    "nhid = 1200\n",
    "\n",
    "transform_covid19 = transforms.Compose([\n",
    "    transforms.Resize(image_resize_size),\n",
    "    transforms.CenterCrop(image_trans_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# transform_covid19 = transforms.Compose([\n",
    "#     transforms.Resize(image_trans_size),\n",
    "#     transforms.CenterCrop(image_trans_size),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     transforms.Grayscale(num_output_channels=1)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d2fae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "\n",
    "\n",
    "def humansize(nbytes):\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes) - 1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes)\n",
    "    return '%s%s' % (f, suffixes[i])\n",
    "\n",
    "\n",
    "def get_num_batches(nb_samples, batch_size, roundup=True):\n",
    "    if roundup:\n",
    "        return ((nb_samples + (-nb_samples % batch_size)) / batch_size)  # roundup division\n",
    "    else:\n",
    "        return nb_samples / batch_size\n",
    "\n",
    "\n",
    "def generate_ind_batch(nb_samples, batch_size, random=True, roundup=True):\n",
    "    if random:\n",
    "        ind = np.random.permutation(nb_samples)\n",
    "    else:\n",
    "        ind = range(int(nb_samples))\n",
    "    for i in range(int(get_num_batches(nb_samples, batch_size, roundup))):\n",
    "        yield ind[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "\n",
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def cprint(color, text, **kwargs):\n",
    "    if color[0] == '*':\n",
    "        pre_code = '1;'\n",
    "        color = color[1:]\n",
    "    else:\n",
    "        pre_code = ''\n",
    "    code = {\n",
    "        'a': '30',\n",
    "        'r': '31',\n",
    "        'g': '32',\n",
    "        'y': '33',\n",
    "        'b': '34',\n",
    "        'p': '35',\n",
    "        'c': '36',\n",
    "        'w': '37'\n",
    "    }\n",
    "    print(\"\\x1b[%s%sm%s\\x1b[0m\" % (pre_code, code[color], text), **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def shuffle_in_unison_scary(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "class Datafeed(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "class DatafeedImage(data.Dataset):\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "\n",
    "### functions for BNN with gauss output: ###\n",
    "\n",
    "def diagonal_gauss_loglike(x, mu, sigma):\n",
    "    # note that we can just treat each dim as isotropic and then do sum\n",
    "    cte_term = -(0.5)*np.log(2*np.pi)\n",
    "    det_sig_term = -torch.log(sigma)\n",
    "    inner = (x - mu)/sigma\n",
    "    dist_term = -(0.5)*(inner**2)\n",
    "    log_px = (cte_term + det_sig_term + dist_term).sum(dim=1, keepdim=False)\n",
    "    return log_px\n",
    "\n",
    "def get_rms(mu, y, y_means, y_stds):\n",
    "    x_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    return torch.sqrt(((x_un - y_un)**2).sum() / y.shape[0])\n",
    "\n",
    "\n",
    "def get_loglike(mu, sigma, y, y_means, y_stds):\n",
    "    mu_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    sigma_un = sigma * y_stds\n",
    "    ll = diagonal_gauss_loglike(y_un, mu_un, sigma_un)\n",
    "    return ll.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d57142d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class BaseNet(object):\n",
    "    def __init__(self):\n",
    "        cprint('c', '\\nNet:')\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return np.sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "    def set_mode_train(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def update_lr(self, epoch, gamma=0.99):\n",
    "        self.epoch += 1\n",
    "        if self.schedule is not None:\n",
    "            if len(self.schedule) == 0 or epoch in self.schedule:\n",
    "                self.lr *= gamma\n",
    "                print('learning rate: %f  (%d)\\n' % self.lr, epoch)\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.lr\n",
    "\n",
    "    def save(self, filename):\n",
    "        cprint('c', 'Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        cprint('c', 'Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d5ec70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def isotropic_gauss_loglike(x, mu, sigma, do_sum=True):\n",
    "    cte_term = -(0.5) * np.log(2 * np.pi)\n",
    "    det_sig_term = -torch.log(sigma)\n",
    "    inner = (x - mu) / sigma\n",
    "    dist_term = -(0.5) * (inner ** 2)\n",
    "\n",
    "    if do_sum:\n",
    "        out = (cte_term + det_sig_term + dist_term).sum()  # sum over all weights\n",
    "    else:\n",
    "        out = (cte_term + det_sig_term + dist_term)\n",
    "    return out\n",
    "\n",
    "\n",
    "class laplace_prior(object):\n",
    "    def __init__(self, mu, b):\n",
    "        self.mu = mu\n",
    "        self.b = b\n",
    "\n",
    "    def loglike(self, x, do_sum=True):\n",
    "        if do_sum:\n",
    "            return (-np.log(2 * self.b) - torch.abs(x - self.mu) / self.b).sum()\n",
    "        else:\n",
    "            return (-np.log(2 * self.b) - torch.abs(x - self.mu) / self.b)\n",
    "\n",
    "\n",
    "class isotropic_gauss_prior(object):\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "        self.cte_term = -(0.5) * np.log(2 * np.pi)\n",
    "        self.det_sig_term = -np.log(self.sigma)\n",
    "\n",
    "    def loglike(self, x, do_sum=True):\n",
    "\n",
    "        dist_term = -(0.5) * ((x - self.mu) / self.sigma) ** 2\n",
    "        if do_sum:\n",
    "            return (self.cte_term + self.det_sig_term + dist_term).sum()\n",
    "        else:\n",
    "            return (self.cte_term + self.det_sig_term + dist_term)\n",
    "\n",
    "\n",
    "class spike_slab_2GMM(object):\n",
    "    def __init__(self, mu1, mu2, sigma1, sigma2, pi):\n",
    "        self.N1 = isotropic_gauss_prior(mu1, sigma1)\n",
    "        self.N2 = isotropic_gauss_prior(mu2, sigma2)\n",
    "\n",
    "        self.pi1 = pi\n",
    "        self.pi2 = (1 - pi)\n",
    "\n",
    "    def loglike(self, x):\n",
    "        N1_ll = self.N1.loglike(x)\n",
    "        N2_ll = self.N2.loglike(x)\n",
    "\n",
    "        # Numerical stability trick -> unnormalising logprobs will underflow otherwise\n",
    "        max_loglike = torch.max(N1_ll, N2_ll)\n",
    "        normalised_like = self.pi1 * torch.exp(N1_ll - max_loglike) + self.pi2 * torch.exp(N2_ll - max_loglike)\n",
    "        loglike = torch.log(normalised_like) + max_loglike\n",
    "\n",
    "        return loglike\n",
    "    \n",
    "# class FlattenLayer(ModuleWrapper):\n",
    "\n",
    "#     def __init__(self, num_features):\n",
    "#         super(FlattenLayer, self).__init__()\n",
    "#         self.num_features = num_features\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x.view(-1, self.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c3d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1eef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183d5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b78e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59161e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f389b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Linear_2L(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, n_hid):\n",
    "#         super(Linear_2L, self).__init__()\n",
    "\n",
    "#         self.n_hid = n_hid\n",
    "\n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#         self.fc1 = nn.Linear(input_dim, self.n_hid)\n",
    "#         self.fc2 = nn.Linear(self.n_hid, self.n_hid)\n",
    "#         self.fc3 = nn.Linear(self.n_hid, output_dim)\n",
    "\n",
    "#         # choose your non linearity\n",
    "#         # self.act = nn.Tanh()\n",
    "#         # self.act = nn.Sigmoid()\n",
    "#         self.act = nn.ReLU(inplace=True)\n",
    "#         # self.act = nn.ELU(inplace=True)\n",
    "#         # self.act = nn.SELU(inplace=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, self.input_dim)  # view(batch_size, input_dim)\n",
    "#         # -----------------\n",
    "#         x = self.fc1(x)\n",
    "#         # -----------------\n",
    "#         x = self.act(x)\n",
    "#         # -----------------\n",
    "#         x = self.fc2(x)\n",
    "#         # -----------------\n",
    "#         x = self.act(x)\n",
    "#         # -----------------\n",
    "#         y = self.fc3(x)\n",
    "\n",
    "#         return y\n",
    "    \n",
    "# class Linear_2L(nn.Module):\n",
    "#     \"\"\"\n",
    "#     To train on CIFAR-10:\n",
    "#     https://arxiv.org/pdf/1207.0580.pdf\n",
    "#     \"\"\"\n",
    "#     def __init__(self, inputs, outputs, side_in):\n",
    "#         super(Linear_2L, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(inputs, 32, 5, stride=1, padding=2),\n",
    "#             nn.Softplus(),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(32, 64, 5, stride=1, padding=2),\n",
    "#             nn.Softplus(),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 128, 5, stride=1, padding=1),\n",
    "#             nn.Softplus(),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             #nn.Flatten()\n",
    "#             #x.view(-1, 2 * 2 * 128).\n",
    "#             nn.Linear(int(side_in/8-2) * int(side_in/8-2) * 128, 1000),\n",
    "#             nn.Softplus(),\n",
    "#             nn.Linear(1000, 1000),\n",
    "#             nn.Softplus(),\n",
    "#             nn.Linear(1000, outputs)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         #print('o',x.size())\n",
    "#         #print(np.shape(x.cpu().numpy()))\n",
    "#         x = x.view(-1, x.size()[2] * x.size()[3] * 128)\n",
    "#         #print('oo',x.size())\n",
    "#         #print(np.shape(x.cpu().numpy()))\n",
    "#         x = self.classifier(x)\n",
    "#         #print('ooo',x.size())\n",
    "#         #print(np.shape(x.cpu().numpy()))\n",
    "#         return x\n",
    "    \n",
    "class Linear_2L(nn.Module):\n",
    "    \"\"\"\n",
    "    To train on CIFAR-10:\n",
    "    https://arxiv.org/pdf/1207.0580.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs, outputs, side_in):\n",
    "        super(Linear_2L, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(inputs, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x\", x)\n",
    "        #plt.imshow(x.cpu())\n",
    "        #print(\"shape\", np.shape(x.cpu()))\n",
    "        x = self.features(x)\n",
    "        #print(\"x1\",x)\n",
    "        #plt.imshow(x.cpu())\n",
    "        #print(\"shape\", np.shape(x.cpu()))\n",
    "        x = self.avgpool(x)\n",
    "        #print(\"x2\",x)\n",
    "        #plt.imshow(x.cpu())\n",
    "        #print(\"shape\", np.shape(x.cpu()))\n",
    "        x = torch.flatten(x, 1)\n",
    "        #print(\"x3\",x)\n",
    "        #plt.imshow(x.cpu())\n",
    "        #print(\"shape\", np.shape(x.cpu()))\n",
    "        x = self.classifier(x)\n",
    "        #print(\"x4\",x)\n",
    "        #plt.imshow(x.cpu())\n",
    "        #print(\"shape\", np.shape(x.cpu()))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Net_langevin(BaseNet):\n",
    "    eps = 1e-6\n",
    "\n",
    "    def __init__(self, lr=1e-3, channels_in=1, side_in=28, cuda=True, classes=2, N_train=60000, \n",
    "                 prior_sig=0, nhid=1200, use_p=False):\n",
    "        super(Net_langevin, self).__init__()\n",
    "        cprint('y', ' Creating Net!! ')\n",
    "        self.lr = lr\n",
    "        self.schedule = None  # [] #[50,200,400,600]\n",
    "        self.cuda = cuda\n",
    "        self.channels_in = channels_in\n",
    "        self.prior_sig = prior_sig\n",
    "        self.classes = classes\n",
    "        self.N_train = N_train\n",
    "        self.side_in = side_in\n",
    "        self.nhid = nhid\n",
    "        self.use_p = use_p\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.weight_set_samples = []\n",
    "        self.test = False\n",
    "\n",
    "    def create_net(self):\n",
    "        self.model = Linear_2L(inputs=self.channels_in, outputs=self.classes, side_in=self.side_in)\n",
    "    #         torch.manual_seed(42)\n",
    "    #         if self.cuda:\n",
    "    #             torch.cuda.manual_seed(42)\n",
    "\n",
    "    #         self.model = Linear_2L(input_dim=self.channels_in * self.side_in * self.side_in, \n",
    "    #                                output_dim=self.classes, n_hid=self.nhid)\n",
    "\n",
    "    #         self.model = Linear_2L(input_dim=self.channels_in * self.side_in * self.side_in, \n",
    "    #                                output_dim=self.classes)\n",
    "\n",
    "\n",
    "\n",
    "        if self.cuda:\n",
    "            self.model.cuda()\n",
    "        #             cudnn.benchmark = True\n",
    "\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "\n",
    "        if self.use_p:\n",
    "            self.optimizer = pSGLD(params=self.model.parameters(), lr=self.lr, \n",
    "                                   norm_sigma=self.prior_sig, addnoise=True)\n",
    "        else:\n",
    "            self.optimizer = SGLD(params=self.model.parameters(), lr=self.lr, \n",
    "                                  norm_sigma=self.prior_sig, addnoise=True)\n",
    "\n",
    "            self.sched = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=10, last_epoch=-1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "        #print(\"before\", self.optimizer)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        out = self.model(x)\n",
    "#         print(\"-------------------------------------------------------------\")\n",
    "#         for i in self.model.parameters():\n",
    "#             print(i.data)\n",
    "        #print(x)\n",
    "        #print(\"after zero_grad(\", self.optimizer)\n",
    "#         print(out)\n",
    "        #print(y)\n",
    "        # We use mean because we treat the loss as an estimation of whole dataset's likelihood\n",
    "        loss = F.cross_entropy(out, y, reduction='mean')\n",
    "#         print(\"loss\", loss)\n",
    "        loss = loss * self.N_train  # We scale the loss to represent the whole dataset\n",
    "        #print(\"loss2\", loss, self.N_train)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # out: (batch_size, out_channels, out_caps_dims)\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        #print('pred', pred)\n",
    "        err = pred.ne(y.data).sum()\n",
    "        #print(\"err\", err)\n",
    "        return loss.data * x.shape[0] / self.N_train, err\n",
    "        #return loss.data * x.shape[0], err\n",
    "\n",
    "    def eval(self, x, y, train=False):\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        loss = F.cross_entropy(out, y, reduction='sum')\n",
    "\n",
    "        probs = F.softmax(out, dim=1).data.cpu()\n",
    "\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data, err, probs\n",
    "\n",
    "    def save_sampled_net(self, max_samples):\n",
    "\n",
    "        if len(self.weight_set_samples) >= max_samples:\n",
    "            self.weight_set_samples.pop(0)\n",
    "\n",
    "        self.weight_set_samples.append(copy.deepcopy(self.model.state_dict()))\n",
    "\n",
    "        cprint('c', ' saving weight samples %d/%d' % (len(self.weight_set_samples), max_samples))\n",
    "\n",
    "        return None\n",
    "\n",
    "    def sample_eval(self, x, y, Nsamples=0, logits=True, train=False):\n",
    "        if Nsamples == 0:\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out[idx] = self.model(x)\n",
    "\n",
    "        if logits:\n",
    "            mean_out = out.mean(dim=0, keepdim=False)\n",
    "            loss = F.cross_entropy(mean_out, y, reduction='sum')\n",
    "            probs = F.softmax(mean_out, dim=1).data.cpu()\n",
    "\n",
    "        else:\n",
    "            mean_out = F.softmax(out, dim=2).mean(dim=0, keepdim=False)\n",
    "            probs = mean_out.data.cpu()\n",
    "\n",
    "            log_mean_probs_out = torch.log(mean_out)\n",
    "            loss = F.nll_loss(log_mean_probs_out, y, reduction='sum')\n",
    "\n",
    "        pred = mean_out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data, err, probs\n",
    "\n",
    "    def all_sample_eval(self, x, y, Nsamples):\n",
    "        if Nsamples == 0:\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out[idx] = self.model(x)\n",
    "\n",
    "        prob_out = F.softmax(out, dim=2)\n",
    "        prob_out = prob_out.data\n",
    "\n",
    "        return prob_out\n",
    "\n",
    "    def get_weight_samples(self, Nsamples=0):\n",
    "        weight_vec = []\n",
    "\n",
    "        if Nsamples == 0 or Nsamples > len(self.weight_set_samples):\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "\n",
    "        for idx, state_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "\n",
    "            for key in state_dict.keys():\n",
    "                if 'weight' in key:\n",
    "                    weight_mtx = state_dict[key].cpu()\n",
    "                    for weight in weight_mtx.view(-1):\n",
    "                        weight_vec.append(weight)\n",
    "\n",
    "        return np.array(weight_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b5f3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SGLD(Optimizer):\n",
    "    \"\"\"\n",
    "    SGLD optimiser based on pytorch's SGD.\n",
    "    Note that the weight decay is specified in terms of the gaussian prior sigma.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=required, norm_sigma=0, addnoise=True):\n",
    "\n",
    "        weight_decay = 1 / (norm_sigma ** 2)\n",
    "\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay, addnoise=addnoise)\n",
    "\n",
    "        super(SGLD, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            weight_decay = group['weight_decay']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "\n",
    "                if group['addnoise']:\n",
    "\n",
    "                    langevin_noise = p.data.new(p.data.size()).normal_(mean=0, std=1) / np.sqrt(group['lr'])\n",
    "                    p.data.add_(-group['lr'],\n",
    "                                0.5 * d_p + langevin_noise)\n",
    "                else:\n",
    "                    p.data.add_(-group['lr'], 0.5 * d_p)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class pSGLD(Optimizer):\n",
    "    \"\"\"\n",
    "    RMSprop preconditioned SGLD using pytorch rmsprop implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=required, norm_sigma=0, alpha=0.99, eps=1e-8, centered=False, addnoise=True):\n",
    "\n",
    "        weight_decay = 1 / (norm_sigma ** 2)\n",
    "\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay, alpha=alpha, eps=eps, centered=centered, addnoise=addnoise)\n",
    "        super(pSGLD, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(pSGLD, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('centered', False)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            weight_decay = group['weight_decay']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['square_avg'] = torch.zeros_like(p.data)\n",
    "                    if group['centered']:\n",
    "                        state['grad_avg'] = torch.zeros_like(p.data)\n",
    "\n",
    "                square_avg = state['square_avg']\n",
    "                alpha = group['alpha']\n",
    "                state['step'] += 1\n",
    "\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "\n",
    "                # sqavg x alpha + (1-alph) sqavg *(elemwise) sqavg\n",
    "                square_avg.mul_(alpha).addcmul_(1 - alpha, d_p, d_p)\n",
    "\n",
    "                if group['centered']:\n",
    "                    grad_avg = state['grad_avg']\n",
    "                    grad_avg.mul_(alpha).add_(1 - alpha, d_p)\n",
    "                    avg = square_avg.cmul(-1, grad_avg, grad_avg).sqrt().add_(group['eps'])\n",
    "                else:\n",
    "                    avg = square_avg.sqrt().add_(group['eps'])\n",
    "\n",
    "                #                 print(avg.shape)\n",
    "                if group['addnoise']:\n",
    "                    langevin_noise = p.data.new(p.data.size()).normal_(mean=0, std=1) / np.sqrt(group['lr'])\n",
    "                    p.data.add_(-group['lr'],\n",
    "                                0.5 * d_p.div_(avg) + langevin_noise / torch.sqrt(avg))\n",
    "\n",
    "                else:\n",
    "                    p.data.addcdiv_(-group['lr'], 0.5 * d_p, avg)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0469f7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33m Creating Net!! \u001b[0m\n",
      "    Total params: 57.01M\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_31124/2671600186.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", \n",
    "                                            transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", \n",
    "                                          transform=transform_covid19)\n",
    "\n",
    "channels_in = trainset[0][0].size()[0]\n",
    "classes = np.shape(np.unique(trainset.targets))[0]\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "# # Where to save models weights\n",
    "# models_dir = args.models_dir\n",
    "# # Where to save plots and error, accuracy vectors\n",
    "# results_dir = args.results_dir\n",
    "\n",
    "if use_preconditioning == 1:\n",
    "    models_dir = 'p' + models_dir\n",
    "    results_dir = 'p' + results_dir\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "# load data\n",
    "\n",
    "# data augmentation\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "# ])\n",
    "#\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "# ])\n",
    "#\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "#\n",
    "# trainset = datasets.MNIST(root='../data', train=True, download=True, transform=transform_train)\n",
    "# valset = datasets.MNIST(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                              shuffle=True, pin_memory=True,num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, \n",
    "                                            shuffle=False, pin_memory=True,num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                              shuffle=True, pin_memory=False,num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, \n",
    "                                            shuffle=False, pin_memory=False,num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "if use_preconditioning == 1:\n",
    "    net = Net_langevin(lr=lr, channels_in=channels_in, side_in=image_trans_size, cuda=use_cuda, \n",
    "                       classes=classes, N_train=NTrainPoints, prior_sig=prior_sig, nhid=nhid, use_p=True)\n",
    "    pstr = 'p'\n",
    "    print('pstr')\n",
    "\n",
    "else:\n",
    "    net = Net_langevin(lr=lr, channels_in=channels_in, side_in=image_trans_size, cuda=use_cuda, \n",
    "                       classes=classes, N_train=NTrainPoints,prior_sig=prior_sig, nhid=nhid, use_p=False)\n",
    "\n",
    "#Net_langevin(lr=lr, channels_in=1, side_in=image_trans_size, cuda=use_cuda, \n",
    "#classes=2, N_train=NTrainPoints, prior_sig=prior_sig)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# train\n",
    "epoch = 0\n",
    "cprint('c', '\\nTrain:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45c297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54326b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef393c3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_31124/3299698679.py:35: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1050.)\n",
      "  d_p.add_(weight_decay, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/100, Jtr_pred = 0.693159, err = 0.500000, \u001b[31m   time: 101.889153 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692979, err = 0.500000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/100, Jtr_pred = 0.693026, err = 0.500000, \u001b[31m   time: 62.594764 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.693034, err = 0.500000\n",
      "\u001b[0m\n",
      "it 2/100, Jtr_pred = 0.692920, err = 0.501500, \u001b[31m   time: 63.052588 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692981, err = 0.500000\n",
      "\u001b[0m\n",
      "it 3/100, Jtr_pred = 0.693063, err = 0.509500, \u001b[31m   time: 62.094626 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692899, err = 0.500000\n",
      "\u001b[0m\n",
      "it 4/100, Jtr_pred = 0.692977, err = 0.506000, \u001b[31m   time: 62.971226 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692993, err = 0.500000\n",
      "\u001b[0m\n",
      "it 5/100, Jtr_pred = 0.693492, err = 0.516000, \u001b[31m   time: 64.087141 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692722, err = 0.498333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 6/100, Jtr_pred = 0.693218, err = 0.504500, \u001b[31m   time: 62.360870 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692555, err = 0.500000\n",
      "\u001b[0m\n",
      "it 7/100, Jtr_pred = 0.693245, err = 0.501000, \u001b[31m   time: 62.398122 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692038, err = 0.500000\n",
      "\u001b[0m\n",
      "it 8/100, Jtr_pred = 0.692708, err = 0.496500, \u001b[31m   time: 62.796096 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692024, err = 0.500000\n",
      "\u001b[0m\n",
      "it 9/100, Jtr_pred = 0.692971, err = 0.504000, \u001b[31m   time: 59.579785 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692600, err = 0.500000\n",
      "\u001b[0m\n",
      "it 10/100, Jtr_pred = 0.692463, err = 0.484000, \u001b[31m   time: 63.290281 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692227, err = 0.498333\n",
      "\u001b[0m\n",
      "it 11/100, Jtr_pred = 0.694110, err = 0.497500, \u001b[31m   time: 58.770181 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.691059, err = 0.493333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 12/100, Jtr_pred = 0.691784, err = 0.490000, \u001b[31m   time: 58.882847 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.691399, err = 0.495000\n",
      "\u001b[0m\n",
      "it 13/100, Jtr_pred = 0.692797, err = 0.494500, \u001b[31m   time: 63.191552 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692750, err = 0.500000\n",
      "\u001b[0m\n",
      "it 14/100, Jtr_pred = 0.695104, err = 0.502000, \u001b[31m   time: 64.071421 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692443, err = 0.465000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 15/100, Jtr_pred = 0.696767, err = 0.496500, \u001b[31m   time: 61.793299 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 1/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692599, err = 0.456667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 16/100, Jtr_pred = 0.697563, err = 0.495000, \u001b[31m   time: 61.718455 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.693372, err = 0.443333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 17/100, Jtr_pred = 0.694331, err = 0.492000, \u001b[31m   time: 56.432402 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692616, err = 0.465000\n",
      "\u001b[0m\n",
      "it 18/100, Jtr_pred = 0.697264, err = 0.496500, \u001b[31m   time: 56.094900 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.691755, err = 0.431667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 19/100, Jtr_pred = 0.696520, err = 0.483000, \u001b[31m   time: 59.886255 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.690582, err = 0.430000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 20/100, Jtr_pred = 0.695526, err = 0.494000, \u001b[31m   time: 58.706293 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 2/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692543, err = 0.458333\n",
      "\u001b[0m\n",
      "it 21/100, Jtr_pred = 0.694209, err = 0.475000, \u001b[31m   time: 58.696613 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.691058, err = 0.450000\n",
      "\u001b[0m\n",
      "it 22/100, Jtr_pred = 0.695439, err = 0.482000, \u001b[31m   time: 59.322594 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.694233, err = 0.503333\n",
      "\u001b[0m\n",
      "it 23/100, Jtr_pred = 0.700120, err = 0.494000, \u001b[31m   time: 57.357365 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.694583, err = 0.536667\n",
      "\u001b[0m\n",
      "it 24/100, Jtr_pred = 0.692649, err = 0.474000, \u001b[31m   time: 60.141012 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.702283, err = 0.515000\n",
      "\u001b[0m\n",
      "it 25/100, Jtr_pred = 0.699463, err = 0.493000, \u001b[31m   time: 56.764934 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 3/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.698876, err = 0.541667\n",
      "\u001b[0m\n",
      "it 26/100, Jtr_pred = 0.700193, err = 0.492000, \u001b[31m   time: 58.028203 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.701055, err = 0.513333\n",
      "\u001b[0m\n",
      "it 27/100, Jtr_pred = 0.696269, err = 0.475500, \u001b[31m   time: 58.437098 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.697692, err = 0.513333\n",
      "\u001b[0m\n",
      "it 28/100, Jtr_pred = 0.699631, err = 0.486500, \u001b[31m   time: 56.876313 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.689252, err = 0.480000\n",
      "\u001b[0m\n",
      "it 29/100, Jtr_pred = 0.697935, err = 0.475500, \u001b[31m   time: 58.083949 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.688927, err = 0.486667\n",
      "\u001b[0m\n",
      "it 30/100, Jtr_pred = 0.697937, err = 0.467500, \u001b[31m   time: 56.896067 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 4/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.683888, err = 0.446667\n",
      "\u001b[0m\n",
      "it 31/100, Jtr_pred = 0.713244, err = 0.485500, \u001b[31m   time: 57.324239 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.692284, err = 0.498333\n",
      "\u001b[0m\n",
      "it 32/100, Jtr_pred = 0.701634, err = 0.477500, \u001b[31m   time: 61.471165 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.680744, err = 0.431667\n",
      "\u001b[0m\n",
      "it 33/100, Jtr_pred = 0.704344, err = 0.452000, \u001b[31m   time: 60.812555 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.681450, err = 0.421667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 34/100, Jtr_pred = 0.706723, err = 0.467000, \u001b[31m   time: 61.745918 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.677508, err = 0.411667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 35/100, Jtr_pred = 0.718232, err = 0.468500, \u001b[31m   time: 61.292809 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 5/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.676355, err = 0.418333\n",
      "\u001b[0m\n",
      "it 36/100, Jtr_pred = 0.710270, err = 0.454500, \u001b[31m   time: 61.764966 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.670713, err = 0.383333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 37/100, Jtr_pred = 0.718018, err = 0.478000, \u001b[31m   time: 62.489121 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.664717, err = 0.388333\n",
      "\u001b[0m\n",
      "it 38/100, Jtr_pred = 0.720410, err = 0.467000, \u001b[31m   time: 62.475492 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.667059, err = 0.378333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 39/100, Jtr_pred = 0.728378, err = 0.471000, \u001b[31m   time: 61.575994 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.658176, err = 0.326667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 40/100, Jtr_pred = 0.714227, err = 0.461500, \u001b[31m   time: 62.810086 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 6/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.659833, err = 0.411667\n",
      "\u001b[0m\n",
      "it 41/100, Jtr_pred = 0.712019, err = 0.442500, \u001b[31m   time: 62.175263 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.650555, err = 0.333333\n",
      "\u001b[0m\n",
      "it 42/100, Jtr_pred = 0.742055, err = 0.476000, \u001b[31m   time: 58.785983 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.653941, err = 0.381667\n",
      "\u001b[0m\n",
      "it 43/100, Jtr_pred = 0.736963, err = 0.464500, \u001b[31m   time: 57.692600 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.655096, err = 0.366667\n",
      "\u001b[0m\n",
      "it 44/100, Jtr_pred = 0.750922, err = 0.471000, \u001b[31m   time: 59.731783 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.653613, err = 0.386667\n",
      "\u001b[0m\n",
      "it 45/100, Jtr_pred = 0.733005, err = 0.461000, \u001b[31m   time: 60.821425 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 7/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.647689, err = 0.383333\n",
      "\u001b[0m\n",
      "it 46/100, Jtr_pred = 0.742470, err = 0.449000, \u001b[31m   time: 59.883740 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.648754, err = 0.423333\n",
      "\u001b[0m\n",
      "it 47/100, Jtr_pred = 0.732581, err = 0.451000, \u001b[31m   time: 58.345381 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.639292, err = 0.388333\n",
      "\u001b[0m\n",
      "it 48/100, Jtr_pred = 0.744517, err = 0.461500, \u001b[31m   time: 60.526318 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.635809, err = 0.400000\n",
      "\u001b[0m\n",
      "it 49/100, Jtr_pred = 0.743043, err = 0.452500, \u001b[31m   time: 55.615391 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.624509, err = 0.308333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 50/100, Jtr_pred = 0.747979, err = 0.437500, \u001b[31m   time: 59.902105 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 8/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622673, err = 0.326667\n",
      "\u001b[0m\n",
      "it 51/100, Jtr_pred = 0.741573, err = 0.449500, \u001b[31m   time: 59.949775 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.620962, err = 0.333333\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 52/100, Jtr_pred = 0.764016, err = 0.460500, \u001b[31m   time: 58.585747 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622261, err = 0.336667\n",
      "\u001b[0m\n",
      "it 53/100, Jtr_pred = 0.733045, err = 0.435500, \u001b[31m   time: 59.049379 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.617620, err = 0.320000\n",
      "\u001b[0m\n",
      "it 54/100, Jtr_pred = 0.754955, err = 0.442000, \u001b[31m   time: 58.375096 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.619238, err = 0.346667\n",
      "\u001b[0m\n",
      "it 55/100, Jtr_pred = 0.745033, err = 0.448500, \u001b[31m   time: 58.703105 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 9/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622175, err = 0.351667\n",
      "\u001b[0m\n",
      "it 56/100, Jtr_pred = 0.766872, err = 0.466500, \u001b[31m   time: 59.850393 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.631406, err = 0.328333\n",
      "\u001b[0m\n",
      "it 57/100, Jtr_pred = 0.732546, err = 0.426500, \u001b[31m   time: 59.044262 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.642526, err = 0.370000\n",
      "\u001b[0m\n",
      "it 58/100, Jtr_pred = 0.773961, err = 0.460500, \u001b[31m   time: 60.637270 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.632067, err = 0.330000\n",
      "\u001b[0m\n",
      "it 59/100, Jtr_pred = 0.769448, err = 0.458000, \u001b[31m   time: 59.816415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.633562, err = 0.361667\n",
      "\u001b[0m\n",
      "it 60/100, Jtr_pred = 0.770120, err = 0.462500, \u001b[31m   time: 58.631305 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 10/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.634717, err = 0.353333\n",
      "\u001b[0m\n",
      "it 61/100, Jtr_pred = 0.767843, err = 0.450000, \u001b[31m   time: 58.075817 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.638188, err = 0.346667\n",
      "\u001b[0m\n",
      "it 62/100, Jtr_pred = 0.769786, err = 0.455500, \u001b[31m   time: 58.510466 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622764, err = 0.323333\n",
      "\u001b[0m\n",
      "it 63/100, Jtr_pred = 0.766581, err = 0.447000, \u001b[31m   time: 58.916788 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.628036, err = 0.333333\n",
      "\u001b[0m\n",
      "it 64/100, Jtr_pred = 0.767729, err = 0.454000, \u001b[31m   time: 56.669184 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.619066, err = 0.316667\n",
      "\u001b[0m\n",
      "it 65/100, Jtr_pred = 0.753355, err = 0.436000, \u001b[31m   time: 58.166881 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 11/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.604873, err = 0.276667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 66/100, Jtr_pred = 0.770438, err = 0.445500, \u001b[31m   time: 61.058314 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.590694, err = 0.300000\n",
      "\u001b[0m\n",
      "it 67/100, Jtr_pred = 0.756735, err = 0.440500, \u001b[31m   time: 58.596949 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.589448, err = 0.260000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGLD_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 68/100, Jtr_pred = 0.743919, err = 0.421500, \u001b[31m   time: 58.568640 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.590218, err = 0.271667\n",
      "\u001b[0m\n",
      "it 69/100, Jtr_pred = 0.746221, err = 0.435500, \u001b[31m   time: 57.555093 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.588874, err = 0.293333\n",
      "\u001b[0m\n",
      "it 70/100, Jtr_pred = 0.775138, err = 0.445000, \u001b[31m   time: 57.502914 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 12/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.590305, err = 0.303333\n",
      "\u001b[0m\n",
      "it 71/100, Jtr_pred = 0.752928, err = 0.421500, \u001b[31m   time: 60.026252 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.589968, err = 0.293333\n",
      "\u001b[0m\n",
      "it 72/100, Jtr_pred = 0.770895, err = 0.430500, \u001b[31m   time: 57.451391 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.596425, err = 0.298333\n",
      "\u001b[0m\n",
      "it 73/100, Jtr_pred = 0.743962, err = 0.416500, \u001b[31m   time: 58.603563 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.598932, err = 0.300000\n",
      "\u001b[0m\n",
      "it 74/100, Jtr_pred = 0.775311, err = 0.436000, \u001b[31m   time: 58.486130 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.596350, err = 0.318333\n",
      "\u001b[0m\n",
      "it 75/100, Jtr_pred = 0.763432, err = 0.447500, \u001b[31m   time: 60.161899 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 13/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.596171, err = 0.310000\n",
      "\u001b[0m\n",
      "it 76/100, Jtr_pred = 0.784572, err = 0.433000, \u001b[31m   time: 60.102545 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.603993, err = 0.323333\n",
      "\u001b[0m\n",
      "it 77/100, Jtr_pred = 0.783057, err = 0.429000, \u001b[31m   time: 57.652938 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.594987, err = 0.331667\n",
      "\u001b[0m\n",
      "it 78/100, Jtr_pred = 0.767193, err = 0.433000, \u001b[31m   time: 57.583966 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.592907, err = 0.333333\n",
      "\u001b[0m\n",
      "it 79/100, Jtr_pred = 0.746328, err = 0.425000, \u001b[31m   time: 58.990698 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.597074, err = 0.321667\n",
      "\u001b[0m\n",
      "it 80/100, Jtr_pred = 0.770686, err = 0.432000, \u001b[31m   time: 57.869167 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 14/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.595634, err = 0.335000\n",
      "\u001b[0m\n",
      "it 81/100, Jtr_pred = 0.784826, err = 0.430000, \u001b[31m   time: 60.845415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.593439, err = 0.335000\n",
      "\u001b[0m\n",
      "it 82/100, Jtr_pred = 0.772323, err = 0.419000, \u001b[31m   time: 56.959064 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.583597, err = 0.315000\n",
      "\u001b[0m\n",
      "it 83/100, Jtr_pred = 0.780926, err = 0.428500, \u001b[31m   time: 60.392073 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.583754, err = 0.325000\n",
      "\u001b[0m\n",
      "it 84/100, Jtr_pred = 0.797353, err = 0.433000, \u001b[31m   time: 58.008079 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.592627, err = 0.301667\n",
      "\u001b[0m\n",
      "it 85/100, Jtr_pred = 0.788538, err = 0.424000, \u001b[31m   time: 62.021898 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 15/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.594027, err = 0.321667\n",
      "\u001b[0m\n",
      "it 86/100, Jtr_pred = 0.771736, err = 0.416500, \u001b[31m   time: 62.302989 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.590364, err = 0.305000\n",
      "\u001b[0m\n",
      "it 87/100, Jtr_pred = 0.768428, err = 0.415000, \u001b[31m   time: 59.432879 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.591548, err = 0.320000\n",
      "\u001b[0m\n",
      "it 88/100, Jtr_pred = 0.812705, err = 0.444500, \u001b[31m   time: 58.640553 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.594178, err = 0.315000\n",
      "\u001b[0m\n",
      "it 89/100, Jtr_pred = 0.796754, err = 0.421500, \u001b[31m   time: 57.555349 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.609321, err = 0.323333\n",
      "\u001b[0m\n",
      "it 90/100, Jtr_pred = 0.771464, err = 0.410000, \u001b[31m   time: 58.772917 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 16/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.583029, err = 0.296667\n",
      "\u001b[0m\n",
      "it 91/100, Jtr_pred = 0.809128, err = 0.427500, \u001b[31m   time: 58.258209 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.576551, err = 0.296667\n",
      "\u001b[0m\n",
      "it 92/100, Jtr_pred = 0.803234, err = 0.422000, \u001b[31m   time: 57.851038 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.572253, err = 0.295000\n",
      "\u001b[0m\n",
      "it 93/100, Jtr_pred = 0.769077, err = 0.414500, \u001b[31m   time: 56.817239 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.581380, err = 0.286667\n",
      "\u001b[0m\n",
      "it 94/100, Jtr_pred = 0.794413, err = 0.418000, \u001b[31m   time: 58.048639 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.606539, err = 0.338333\n",
      "\u001b[0m\n",
      "it 95/100, Jtr_pred = 0.814154, err = 0.430000, \u001b[31m   time: 57.946180 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 17/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.569387, err = 0.315000\n",
      "\u001b[0m\n",
      "it 96/100, Jtr_pred = 0.752434, err = 0.394500, \u001b[31m   time: 56.913011 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.604573, err = 0.345000\n",
      "\u001b[0m\n",
      "it 97/100, Jtr_pred = 0.801053, err = 0.401500, \u001b[31m   time: 60.093936 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.592165, err = 0.306667\n",
      "\u001b[0m\n",
      "it 98/100, Jtr_pred = 0.811437, err = 0.407000, \u001b[31m   time: 56.475939 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.624150, err = 0.350000\n",
      "\u001b[0m\n",
      "it 99/100, Jtr_pred = 0.785841, err = 0.393500, \u001b[31m   time: 56.633246 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.600847, err = 0.328333\n",
      "\u001b[0m\n",
      "\u001b[31m   average time: 78.874980 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m\n",
      "RESULTS:\u001b[0m\n",
      "  cost_dev: 0.569387 (cost_train 0.691784)\n",
      "  err_dev: 0.260000\n",
      "  nb_parameters: 57012034 (54.37MB)\n",
      "  time_per_it: 78.874980s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_31124/2671600186.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    }
   ],
   "source": [
    "start_save = 15\n",
    "\n",
    "N_saves = 100  # Max number of saves\n",
    "###################################\n",
    "\n",
    "print('  init cost variables:')\n",
    "kl_cost_train = np.zeros(nb_epochs)\n",
    "pred_cost_train = np.zeros(nb_epochs)\n",
    "err_train = np.zeros(nb_epochs)\n",
    "\n",
    "cost_dev = np.zeros(nb_epochs)\n",
    "err_dev = np.zeros(nb_epochs)\n",
    "best_err = np.inf\n",
    "\n",
    "nb_its_dev = 1\n",
    "\n",
    "tic0 = time.time()\n",
    "for i in range(epoch, nb_epochs):\n",
    "\n",
    "    net.set_mode_train(True)\n",
    "    tic = time.time()\n",
    "    nb_samples = 0\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        #x = x[:,0,:,:]\n",
    "        #print(x.cpu().numpy().shape())\n",
    "        cost_pred, err = net.fit(x, y)\n",
    "\n",
    "        err_train[i] += err\n",
    "        pred_cost_train[i] += cost_pred\n",
    "        nb_samples += len(x)\n",
    "        #print('ccc', cost_pred, nb_samples, len(x))\n",
    "    #print('i', nb_samples)\n",
    "    pred_cost_train[i] /= nb_samples\n",
    "    err_train[i] /= nb_samples\n",
    "\n",
    "    toc = time.time()\n",
    "    net.epoch = i\n",
    "    # ---- print\n",
    "    print(\"it %d/%d, Jtr_pred = %f, err = %f, \" % (i, nb_epochs, pred_cost_train[i], err_train[i]), end=\"\")\n",
    "    cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "\n",
    "    # ---- save weights\n",
    "    if i >= start_save and i % save_every == 0:\n",
    "        net.save_sampled_net(max_samples=N_saves)\n",
    "\n",
    "    # ---- dev\n",
    "    if i % nb_its_dev == 0:\n",
    "        net.set_mode_train(False)\n",
    "        nb_samples = 0\n",
    "        for j, (x, y) in enumerate(valloader):\n",
    "            cost, err, probs = net.eval(x, y)\n",
    "\n",
    "            cost_dev[i] += cost\n",
    "            err_dev[i] += err\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        cost_dev[i] /= nb_samples\n",
    "        err_dev[i] /= nb_samples\n",
    "\n",
    "        cprint('g', '    Jdev = %f, err = %f\\n' % (cost_dev[i], err_dev[i]))\n",
    "\n",
    "        if err_dev[i] < best_err:\n",
    "            best_err = err_dev[i]\n",
    "            cprint('b', 'best test error')\n",
    "            net.save(models_dir+'/theta_best.dat')\n",
    "\n",
    "toc0 = time.time()\n",
    "runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "# Save weight samples from the posterior\n",
    "save_object(net.weight_set_samples, models_dir+'/state_dicts.pkl')\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# results\n",
    "cprint('c', '\\nRESULTS:')\n",
    "nb_parameters = net.get_nb_parameters()\n",
    "best_cost_dev = np.min(cost_dev)\n",
    "best_cost_train = np.min(pred_cost_train)\n",
    "err_dev_min = err_dev[::nb_its_dev].min()\n",
    "\n",
    "print('  cost_dev: %f (cost_train %f)' % (best_cost_dev, best_cost_train))\n",
    "print('  err_dev: %f' % (err_dev_min))\n",
    "print('  nb_parameters: %d (%s)' % (nb_parameters, humansize(nb_parameters)))\n",
    "print('  time_per_it: %fs\\n' % (runtime_per_it))\n",
    "\n",
    "## Save results for plots\n",
    "np.save(results_dir + '/cost_train.npy', pred_cost_train)\n",
    "np.save(results_dir + '/cost_dev.npy', cost_dev)\n",
    "np.save(results_dir + '/err_train.npy', err_train)\n",
    "np.save(results_dir + '/err_dev.npy', err_dev)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# fig cost vs its\n",
    "\n",
    "textsize = 15\n",
    "marker = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b8eb42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_31124/2542181615.py:34: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=100)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(0, nb_epochs, nb_its_dev), cost_dev[::nb_its_dev], 'b-')\n",
    "ax1.plot(pred_cost_train, 'r--')\n",
    "ax1.set_ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "plt.title('classification costs')\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/cost.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_ylabel('% error')\n",
    "ax2.plot(range(0, nb_epochs, nb_its_dev), 100 * err_dev[::nb_its_dev], 'b-')\n",
    "ax2.plot(100 * err_train, 'r--')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "ax2.get_yaxis().set_minor_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax2.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afbc9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea0ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5741a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c351f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ad80eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e7c0f",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0519266d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_dir models_SGLD_COVID150\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33m Creating Net!! \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_31124/2671600186.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 57.01M\n",
      "predict SGLD in\n",
      "\u001b[34m    Loglike = -377.276703, err = 0.283333\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", transform=transform_covid19)\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "\n",
    "if use_preconditioning == 1:\n",
    "    print('ccccc')\n",
    "    models_dir = 'p' + models_dir\n",
    "    results_dir = 'p' + results_dir\n",
    "\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "print('models_dir', models_dir)\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                              shuffle=False, pin_memory=True,num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, \n",
    "                                            shuffle=False, pin_memory=True,num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                              shuffle=False, pin_memory=False,num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, \n",
    "                                            shuffle=False, pin_memory=False, num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "if use_preconditioning == 1:\n",
    "    net = Net_langevin(lr=lr, channels_in=channels_in, side_in=image_trans_size, \n",
    "                       cuda=use_cuda, classes=classes, N_train=NTrainPoints,prior_sig=prior_sig, \n",
    "                       nhid=nhid, use_p=True)\n",
    "    pstr = 'p'\n",
    "    print('predict pSGLD in')\n",
    "else:\n",
    "    net = Net_langevin(lr=lr, channels_in=channels_in, side_in=image_trans_size, \n",
    "                       cuda=use_cuda, classes=classes, N_train=NTrainPoints,prior_sig=prior_sig, \n",
    "                       nhid=nhid, use_p=False)\n",
    "    print(\"predict SGLD in\")\n",
    "\n",
    "if use_preconditioning == 1:\n",
    "    pstr = 'p'\n",
    "    with open(models_dir + '/state_dicts.pkl', 'rb') as input:\n",
    "        net.weight_set_samples = pickle.load(input)\n",
    "else:\n",
    "    with open(models_dir + '/state_dicts.pkl', 'rb') as input:\n",
    "        net.weight_set_samples = pickle.load(input)\n",
    "\n",
    "if use_cuda:\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                            num_workers=num_workers)\n",
    "test_cost = 0  # Note that these are per sample\n",
    "test_err = 0\n",
    "nb_samples = 0\n",
    "test_predictions = np.zeros((test_data_len, classes))\n",
    "\n",
    "\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "for j, (x, y) in enumerate(valloader):\n",
    "    cost, err, probs = net.sample_eval(x, y, Nsamples, logits=False) # , logits=True\n",
    "    #print('nettttttttttttttttttttttttttttttttttt', probs)\n",
    "    test_cost += cost\n",
    "    test_err += err.cpu().numpy()\n",
    "    test_predictions[nb_samples:nb_samples+len(x), :] = probs.numpy()\n",
    "    nb_samples += len(x)\n",
    "\n",
    "# test_cost /= nb_samples\n",
    "test_err /= nb_samples\n",
    "cprint('b', '    Loglike = %5.6f, err = %1.6f\\n' % (-test_cost, test_err))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947eec94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image number: 452\n",
      "real number: 1\n",
      "error 0\n",
      "predict 1\n",
      "452\n",
      "{'0noncovid': 0, '1covid': 1}\n"
     ]
    }
   ],
   "source": [
    "x_dev = []\n",
    "y_dev = []\n",
    "for x, y in valloader:\n",
    "    x_dev.append(x.cpu().numpy())\n",
    "    y_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_dev = np.concatenate(x_dev)\n",
    "y_dev = np.concatenate(y_dev)\n",
    "#print(x_dev.shape)\n",
    "#print(y_dev.shape)\n",
    "\n",
    "im_ind = np.random.randint(0, y_dev.shape[0])\n",
    "#im_ind = 90\n",
    "print(\"image number:\", im_ind)\n",
    "\n",
    "\n",
    "x, y = x_dev[im_ind], y_dev[im_ind]\n",
    "#x_rot = np.expand_dims(ndim.interpolation.rotate(x[:, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "\n",
    "print(\"real number:\", y)\n",
    "\n",
    "#plt.imshow(ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "\n",
    "\n",
    "ims=[]\n",
    "\n",
    "\n",
    "#ims.append(x_rot[:,:,:])\n",
    "ims.append(x)\n",
    "\n",
    "\n",
    "#ims = np.concatenate(ims)\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "y = np.ones(np.shape(ims)[0])*y\n",
    "#ims = np.expand_dims(ims, axis=1)\n",
    "ims = np.array(ims)\n",
    "\n",
    "cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), \n",
    "                                   Nsamples=Nsamples, logits=False) # , logits=True\n",
    "\n",
    "predictions = probs.numpy()\n",
    "\n",
    "#print(\"predictions\", predictions)\n",
    "\n",
    "print(\"error\", err.cpu().numpy())\n",
    "\n",
    "\n",
    "# predictions.max(axis=1)[0]\n",
    "# selections = (predictions[:,i] == predictions.max(axis=1))\n",
    "print(\"predict\", predictions.argmax())\n",
    "\n",
    "print(im_ind)\n",
    "\n",
    "#print(valset[im_ind][1])\n",
    "\n",
    "print(valset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a72043",
   "metadata": {},
   "source": [
    "# predict train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50dba3b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "859aa1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_dev = []\n",
    "y_train_dev = []\n",
    "for x, y in trainloader:\n",
    "    x_train_dev.append(x.cpu().numpy())\n",
    "    y_train_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_train_dev = np.concatenate(x_train_dev)\n",
    "y_train_dev = np.concatenate(y_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7dd139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8f087de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "c SGLD_predict_data\\SGLD_train_epochs=100_lr=0.000000_batch_size=20_image_trans_size=224.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,train_data_len):\n",
    "    x, y = x_train_dev[i], y_train_dev[i]\n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    #print(y)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, logits=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(train_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGLD_predict_data'\n",
    "    if use_preconditioning == 1:\n",
    "        save_path = pstr + save_path\n",
    "        print('in pSGLD path', save_path)\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGLD_train_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")\n",
    "    # file1 = open(completeName, \"w\")\n",
    "    # for i in range(0, 41):\n",
    "    #\n",
    "    #     file1.write(str(prob[i]))\n",
    "    #     file1.write(\"\\n\")\n",
    "    # file1.close()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0caa0",
   "metadata": {},
   "source": [
    "# predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad7b6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd08dddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "c SGLD_predict_data\\SGLD_epochs=100_lr=0.000000_batch_size=20_image_trans_size=224.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,test_data_len):\n",
    "    x, y = x_dev[i], y_dev[i]\n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    #print(y)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, logits=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(test_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGLD_predict_data'\n",
    "    if use_preconditioning == 1:\n",
    "        save_path = pstr + save_path\n",
    "        print('in pSGLD path', save_path)\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGLD_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")\n",
    "    # file1 = open(completeName, \"w\")\n",
    "    # for i in range(0, 41):\n",
    "    #\n",
    "    #     file1.write(str(prob[i]))\n",
    "    #     file1.write(\"\\n\")\n",
    "    # file1.close()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d88e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901ad9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ca523d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5c414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907751e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654040a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e420906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4e7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
