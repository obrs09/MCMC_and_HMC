{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9923264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndim\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import collections\n",
    "import h5py, sys\n",
    "import gzip\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from numpy.random import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecda9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_resize_size = 256\n",
    "image_trans_size = 128\n",
    "batch_size = 40\n",
    "nb_epochs = 100\n",
    "\n",
    "pSGLD = False\n",
    "save_data = True\n",
    "n_samples = 90\n",
    "\n",
    "sample_freq = 2\n",
    "burn_in = 1000\n",
    "\n",
    "\n",
    "\n",
    "prior_sig = 0.1\n",
    "# Where to save models weights\n",
    "models_dir = 'models_SGHMC_COVID150'\n",
    "# Where to save plots and error, accuracy vectors\n",
    "results_dir = 'results_SGHMC_COVID150'\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model= 'Gaussian_prior'\n",
    "nsamples = int(n_samples)\n",
    "\n",
    "\n",
    "## weight saving parameters #######\n",
    "\n",
    "\n",
    "N_saves = 100\n",
    "resample_its = 50\n",
    "resample_prior_its = 15\n",
    "re_burn = 1e8\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## weight saving parameters #######\n",
    "\n",
    "sim_steps = 5\n",
    "\n",
    "###################################\n",
    "\n",
    "Nsamples = nsamples\n",
    "\n",
    "save_every = int(nb_epochs/20)  \n",
    "# We sample every 2 epochs as I have found samples to be correlated after only 1\n",
    "num_workers = 4\n",
    "nhid = 1200\n",
    "\n",
    "grad_std_mul=20\n",
    "\n",
    "transform_covid19 = transforms.Compose([\n",
    "    transforms.Resize(image_trans_size),\n",
    "    transforms.CenterCrop(image_trans_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Grayscale(num_output_channels=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b5e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d20a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "\n",
    "\n",
    "def humansize(nbytes):\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes) - 1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes)\n",
    "    return '%s%s' % (f, suffixes[i])\n",
    "\n",
    "\n",
    "def get_num_batches(nb_samples, batch_size, roundup=True):\n",
    "    if roundup:\n",
    "        return ((nb_samples + (-nb_samples % batch_size)) / batch_size)  # roundup division\n",
    "    else:\n",
    "        return nb_samples / batch_size\n",
    "\n",
    "\n",
    "def generate_ind_batch(nb_samples, batch_size, random=True, roundup=True):\n",
    "    if random:\n",
    "        ind = np.random.permutation(nb_samples)\n",
    "    else:\n",
    "        ind = range(int(nb_samples))\n",
    "    for i in range(int(get_num_batches(nb_samples, batch_size, roundup))):\n",
    "        yield ind[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "\n",
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def cprint(color, text, **kwargs):\n",
    "    if color[0] == '*':\n",
    "        pre_code = '1;'\n",
    "        color = color[1:]\n",
    "    else:\n",
    "        pre_code = ''\n",
    "    code = {\n",
    "        'a': '30',\n",
    "        'r': '31',\n",
    "        'g': '32',\n",
    "        'y': '33',\n",
    "        'b': '34',\n",
    "        'p': '35',\n",
    "        'c': '36',\n",
    "        'w': '37'\n",
    "    }\n",
    "    print(\"\\x1b[%s%sm%s\\x1b[0m\" % (pre_code, code[color], text), **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def shuffle_in_unison_scary(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "class Datafeed(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "class DatafeedImage(data.Dataset):\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "\n",
    "### functions for BNN with gauss output: ###\n",
    "\n",
    "def diagonal_gauss_loglike(x, mu, sigma):\n",
    "    # note that we can just treat each dim as isotropic and then do sum\n",
    "    cte_term = -(0.5)*np.log(2*np.pi)\n",
    "    det_sig_term = -torch.log(sigma)\n",
    "    inner = (x - mu)/sigma\n",
    "    dist_term = -(0.5)*(inner**2)\n",
    "    log_px = (cte_term + det_sig_term + dist_term).sum(dim=1, keepdim=False)\n",
    "    return log_px\n",
    "\n",
    "def get_rms(mu, y, y_means, y_stds):\n",
    "    x_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    return torch.sqrt(((x_un - y_un)**2).sum() / y.shape[0])\n",
    "\n",
    "\n",
    "def get_loglike(mu, sigma, y, y_means, y_stds):\n",
    "    mu_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    sigma_un = sigma * y_stds\n",
    "    ll = diagonal_gauss_loglike(y_un, mu_un, sigma_un)\n",
    "    return ll.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0584ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BaseNet(object):\n",
    "    def __init__(self):\n",
    "        cprint('c', '\\nNet:')\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return np.sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "    def set_mode_train(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def update_lr(self, epoch, gamma=0.99):\n",
    "        self.epoch += 1\n",
    "        if self.schedule is not None:\n",
    "            if len(self.schedule) == 0 or epoch in self.schedule:\n",
    "                self.lr *= gamma\n",
    "                print('learning rate: %f  (%d)\\n' % self.lr, epoch)\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.lr\n",
    "\n",
    "    def save(self, filename):\n",
    "        cprint('c', 'Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        cprint('c', 'Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class H_SA_SGHMC(Optimizer):\n",
    "    \"\"\" Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses scale adaption during burn-in\n",
    "        procedure to find some hyperparamters. A gaussian prior is placed over parameters and a Gamma\n",
    "        Hyperprior is placed over the prior's standard deviation\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-2, base_C=0.05, gauss_sig=0.1, alpha0=10, beta0=10):\n",
    "\n",
    "        self.eps = 1e-6\n",
    "        self.alpha0 = alpha0\n",
    "        self.beta0 = beta0\n",
    "\n",
    "        if gauss_sig == 0:\n",
    "            self.weight_decay = 0\n",
    "        else:\n",
    "            self.weight_decay = 1 / (gauss_sig ** 2)\n",
    "\n",
    "        if self.weight_decay <= 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if base_C < 0:\n",
    "            raise ValueError(\"Invalid friction term: {}\".format(base_C))\n",
    "\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            base_C=base_C,\n",
    "        )\n",
    "        super(H_SA_SGHMC, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, burn_in=False, resample_momentum=False, resample_prior=False):\n",
    "        \"\"\"Simulate discretized Hamiltonian dynamics for one step\"\"\"\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:  # iterate over blocks -> the ones defined in defaults. We dont use groups.\n",
    "            for p in group[\"params\"]:  # these are weight and bias matrices\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]  # define dict for each individual param\n",
    "                if len(state) == 0:\n",
    "                    state[\"iteration\"] = 0\n",
    "                    state[\"tau\"] = torch.ones_like(p)\n",
    "                    state[\"g\"] = torch.ones_like(p)\n",
    "                    state[\"V_hat\"] = torch.ones_like(p)\n",
    "                    state[\"v_momentum\"] = torch.zeros_like(\n",
    "                        p)  # p.data.new(p.data.size()).normal_(mean=0, std=np.sqrt(group[\"lr\"])) #\n",
    "                    state['weight_decay'] = self.weight_decay\n",
    "\n",
    "                state[\"iteration\"] += 1  # this is kind of useless now but lets keep it provisionally\n",
    "\n",
    "                if resample_prior:\n",
    "                    alpha = self.alpha0 + p.data.nelement() / 2\n",
    "                    beta = self.beta0 + (p.data ** 2).sum().item() / 2\n",
    "                    gamma_sample = gamma(shape=alpha, scale=1 / (beta), size=None)\n",
    "                    #                     print('std', 1/np.sqrt(gamma_sample))\n",
    "                    state['weight_decay'] = gamma_sample\n",
    "\n",
    "                base_C, lr = group[\"base_C\"], group[\"lr\"]\n",
    "                weight_decay = state[\"weight_decay\"]\n",
    "                tau, g, V_hat = state[\"tau\"], state[\"g\"], state[\"V_hat\"]\n",
    "\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "\n",
    "                # update parameters during burn-in\n",
    "                if burn_in:  # We update g first as it makes most sense\n",
    "                    tau.add_(-tau * (g ** 2) / (\n",
    "                                V_hat + self.eps) + 1)  # specifies the moving average window, see Eq 9 in [1] left\n",
    "                    tau_inv = 1. / (tau + self.eps)\n",
    "                    g.add_(-tau_inv * g + tau_inv * d_p)  # average gradient see Eq 9 in [1] right\n",
    "                    V_hat.add_(-tau_inv * V_hat + tau_inv * (d_p ** 2))  # gradient variance see Eq 8 in [1]\n",
    "\n",
    "                V_sqrt = torch.sqrt(V_hat)\n",
    "                V_inv_sqrt = 1. / (V_sqrt + self.eps)  # preconditioner\n",
    "\n",
    "                if resample_momentum:  # equivalent to var = M under momentum reparametrisation\n",
    "                    state[\"v_momentum\"] = torch.normal(mean=torch.zeros_like(d_p),\n",
    "                                                       std=torch.sqrt((lr ** 2) * V_inv_sqrt))\n",
    "                v_momentum = state[\"v_momentum\"]\n",
    "\n",
    "                noise_var = (2. * (lr ** 2) * V_inv_sqrt * base_C - (lr ** 4))\n",
    "                noise_std = torch.sqrt(torch.clamp(noise_var, min=1e-16))\n",
    "                # sample random epsilon\n",
    "                noise_sample = torch.normal(mean=torch.zeros_like(d_p), std=torch.ones_like(d_p) * noise_std)\n",
    "\n",
    "                # update momentum (Eq 10 right in [1])\n",
    "                v_momentum.add_(- (lr ** 2) * V_inv_sqrt * d_p - base_C * v_momentum + noise_sample)\n",
    "\n",
    "                # update theta (Eq 10 left in [1])\n",
    "                p.data.add_(v_momentum)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef19b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "\n",
    "        layers = [nn.Linear(input_dim, width), nn.ReLU()]\n",
    "        for i in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BNN_cat(BaseNet):  # for categorical distributions\n",
    "    def __init__(self, channels_in=1, side_in=224, classes=2, N_train = 300, lr=1e-2, cuda=True, grad_std_mul=30):\n",
    "        super(BNN_cat, self).__init__()\n",
    "\n",
    "        cprint('y', 'BNN categorical output')\n",
    "        self.lr = lr\n",
    "        self.channels_in = channels_in\n",
    "        self.side_in = side_in\n",
    "        self.classes = classes\n",
    "        self.model = MLP(input_dim=self.channels_in * self.side_in * self.side_in, width=1200, depth=2, output_dim=self.classes)\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.N_train = N_train\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.schedule = None  # [] #[50,200,400,600]\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.grad_buff = []\n",
    "        self.max_grad = 1e20\n",
    "        self.grad_std_mul = grad_std_mul\n",
    "\n",
    "        self.weight_set_samples = []\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        if self.cuda:\n",
    "            torch.cuda.manual_seed(42)\n",
    "        if self.cuda:\n",
    "            self.model.cuda()\n",
    "\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        \"\"\"This optimiser incorporates the gaussian prior term automatically. The prior variance is gibbs sampled from\n",
    "        its posterior using a gamma hyper-prior.\"\"\"\n",
    "        self.optimizer = H_SA_SGHMC(params=self.model.parameters(), lr=self.lr, base_C=0.05, gauss_sig=0.1)  # this last parameter does nothing\n",
    "\n",
    "    def fit(self, x, y, burn_in=False, resample_momentum=False, resample_prior=False):\n",
    "        self.set_mode_train(train=True)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = F.cross_entropy(out, y, reduction='mean')\n",
    "        loss = loss * self.N_train  # We use mean because we treat as an estimation of whole dataset\n",
    "        loss.backward()\n",
    "        #print('len', len(self.grad_buff))\n",
    "        #print([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))])\n",
    "        # Gradient buffer to allow for dynamic clipping and prevent explosions\n",
    "        if len(self.grad_buff) > 1000:\n",
    "            #self.grad_buff = [self.grad_buff[i].cpu() for i in range(len(self.grad_buff))]\n",
    "            #print('len',len(self.grad_buff), self.grad_buff)\n",
    "            #print(type(self.grad_buff))\n",
    "            #print(np.array(self.grad_buff))\n",
    "\n",
    "            self.max_grad = np.mean([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))]) + self.grad_std_mul * np.std([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))])\n",
    "            self.grad_buff.pop(0)\n",
    "        # Clipping to prevent explosions\n",
    "        self.grad_buff.append(nn.utils.clip_grad_norm_(parameters=self.model.parameters(),\n",
    "                                                       max_norm=self.max_grad, norm_type=2))\n",
    "        if self.grad_buff[-1] >= self.max_grad:\n",
    "            print(self.max_grad, self.grad_buff[-1])\n",
    "            self.grad_buff.pop()\n",
    "        self.optimizer.step(burn_in=burn_in, resample_momentum=resample_momentum, resample_prior=resample_prior)\n",
    "\n",
    "        # out: (batch_size, out_channels, out_caps_dims)\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data * x.shape[0] / self.N_train, err\n",
    "\n",
    "    def eval(self, x, y, train=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "\n",
    "        out = self.model(x)\n",
    "        loss = F.cross_entropy(out, y, reduction='sum')\n",
    "        probs = F.softmax(out, dim=1).data.cpu()\n",
    "\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data, err, probs\n",
    "\n",
    "    def save_sampled_net(self, max_samples):\n",
    "\n",
    "        if len(self.weight_set_samples) >= max_samples:\n",
    "            self.weight_set_samples.pop(0)\n",
    "\n",
    "        self.weight_set_samples.append(copy.deepcopy(self.model.state_dict()))\n",
    "\n",
    "        cprint('c', ' saving weight samples %d/%d' % (len(self.weight_set_samples), max_samples))\n",
    "        return None\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        out = self.model(x)\n",
    "        probs = F.softmax(out, dim=1).data.cpu()\n",
    "        return probs.data\n",
    "\n",
    "    def sample_predict(self, x, Nsamples=0, grad=False):\n",
    "        \"\"\"return predictions using multiple samples from posterior\"\"\"\n",
    "        self.set_mode_train(train=False)\n",
    "        if Nsamples == 0:\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "\n",
    "        if grad:\n",
    "            self.optimizer.zero_grad()\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out[idx] = self.model(x)\n",
    "\n",
    "        out = out[:idx]\n",
    "        prob_out = F.softmax(out, dim=2)\n",
    "\n",
    "        if grad:\n",
    "            return prob_out\n",
    "        else:\n",
    "            return prob_out.data\n",
    "\n",
    "    def sample_eval(self, x, y, Nsamples=0, grad=False):\n",
    "        #print('in sample_eval')\n",
    "        \"\"\"return predictions using multiple samples from posterior\"\"\"\n",
    "        self.set_mode_train(train=False)\n",
    "        if Nsamples == 0:\n",
    "            #print('Nsamples=0')\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "        \n",
    "        \n",
    "        if grad:\n",
    "            print('grad')\n",
    "            self.optimizer.zero_grad()\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "        #print('momomomomo', len(self.weight_set_samples))\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            #print('ccccccc', self.model, x.size()[0])\n",
    "            #print('mmmmmmm', x.resize_(x.size()[0], self.side_in * self.side_in).size())\n",
    "            out[idx] = self.model(x.resize_(x.size()[0], self.side_in * self.side_in))\n",
    "\n",
    "        #print('idxxxxxxxxxx', idx)\n",
    "        out = out[:idx]\n",
    "\n",
    "        mean_out = F.softmax(out, dim=2).mean(dim=0, keepdim=False)\n",
    "\n",
    "        loss = F.cross_entropy(mean_out, y, reduction='sum')\n",
    "        prob_out = F.softmax(mean_out, dim=1).data.cpu()\n",
    "\n",
    "        pred = mean_out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        if grad:\n",
    "            return loss.data, err, prob_out\n",
    "        else:\n",
    "            return loss.data, err, prob_out\n",
    "\n",
    "    def get_weight_samples(self, Nsamples=0):\n",
    "        \"\"\"return weight samples from posterior in a single-column array\"\"\"\n",
    "        weight_vec = []\n",
    "\n",
    "        if Nsamples == 0 or Nsamples > len(self.weight_set_samples):\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "\n",
    "        for idx, state_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "\n",
    "            for key in state_dict.keys():\n",
    "                if 'weight' in key:\n",
    "                    weight_mtx = state_dict[key].cpu().data\n",
    "                    for weight in weight_mtx.view(-1):\n",
    "                        weight_vec.append(weight)\n",
    "\n",
    "        return np.array(weight_vec)\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        save_object(self.weight_set_samples, filename)\n",
    "\n",
    "    def load_weights(self, filename, subsample=1):\n",
    "        self.weight_set_samples = load_object(filename)\n",
    "        self.weight_set_samples = self.weight_set_samples[::subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5790c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f17b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80712553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", transform=transform_covid19)\n",
    "\n",
    "\n",
    "channels_in = trainset[0][0].size()[0]\n",
    "classes = np.shape(np.unique(trainset.targets))[0]\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "nb_its_dev = log_interval\n",
    "flat_ims = True\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "# load data\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba9e19a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mBNN categorical output\u001b[0m\n",
      "    Total params: 21.11M\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_3524/272664775.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_3524/1161784216.py:63: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1050.)\n",
      "  d_p.add_(weight_decay, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/100, Jtr_pred = 0.704541, err = 0.510000, \u001b[31m   time: 56.890023 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 1/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.699331, err = 0.503333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/100, Jtr_pred = 0.700707, err = 0.496500, \u001b[31m   time: 55.600485 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.672427, err = 0.405000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 2/100, Jtr_pred = 0.681002, err = 0.443000, \u001b[31m   time: 59.155406 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.681616, err = 0.430000\n",
      "\u001b[0m\n",
      "it 3/100, Jtr_pred = 0.669175, err = 0.403500, \u001b[31m   time: 56.556102 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.693274, err = 0.413333\n",
      "\u001b[0m\n",
      "it 4/100, Jtr_pred = 0.660356, err = 0.389000, \u001b[31m   time: 55.066005 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.644438, err = 0.350000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 5/100, Jtr_pred = 0.654714, err = 0.377500, \u001b[31m   time: 55.281515 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 2/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.660442, err = 0.398333\n",
      "\u001b[0m\n",
      "it 6/100, Jtr_pred = 0.667205, err = 0.408500, \u001b[31m   time: 55.722930 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.666327, err = 0.430000\n",
      "\u001b[0m\n",
      "it 7/100, Jtr_pred = 0.663662, err = 0.385500, \u001b[31m   time: 60.279431 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.655405, err = 0.388333\n",
      "\u001b[0m\n",
      "it 8/100, Jtr_pred = 0.653559, err = 0.366500, \u001b[31m   time: 53.844444 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.666563, err = 0.366667\n",
      "\u001b[0m\n",
      "it 9/100, Jtr_pred = 0.653604, err = 0.369500, \u001b[31m   time: 55.475854 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.646591, err = 0.365000\n",
      "\u001b[0m\n",
      "it 10/100, Jtr_pred = 0.652792, err = 0.356500, \u001b[31m   time: 55.376861 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 3/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.626050, err = 0.331667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 11/100, Jtr_pred = 0.651036, err = 0.375000, \u001b[31m   time: 57.132183 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.651461, err = 0.381667\n",
      "\u001b[0m\n",
      "it 12/100, Jtr_pred = 0.643017, err = 0.376000, \u001b[31m   time: 54.901302 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.628191, err = 0.336667\n",
      "\u001b[0m\n",
      "it 13/100, Jtr_pred = 0.640679, err = 0.347500, \u001b[31m   time: 54.045582 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.640887, err = 0.331667\n",
      "\u001b[0m\n",
      "it 14/100, Jtr_pred = 0.647213, err = 0.353000, \u001b[31m   time: 55.227745 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.641278, err = 0.330000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 15/100, Jtr_pred = 0.639299, err = 0.342000, \u001b[31m   time: 53.572372 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 4/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.665210, err = 0.336667\n",
      "\u001b[0m\n",
      "it 16/100, Jtr_pred = 0.645766, err = 0.345500, \u001b[31m   time: 57.438686 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.647849, err = 0.331667\n",
      "\u001b[0m\n",
      "it 17/100, Jtr_pred = 0.636723, err = 0.335000, \u001b[31m   time: 54.883151 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.675654, err = 0.338333\n",
      "\u001b[0m\n",
      "it 18/100, Jtr_pred = 0.622805, err = 0.322500, \u001b[31m   time: 55.301134 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.659451, err = 0.325000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 19/100, Jtr_pred = 0.663516, err = 0.342000, \u001b[31m   time: 54.782021 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.655455, err = 0.336667\n",
      "\u001b[0m\n",
      "it 20/100, Jtr_pred = 0.642423, err = 0.314000, \u001b[31m   time: 55.245595 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 5/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.661886, err = 0.338333\n",
      "\u001b[0m\n",
      "it 21/100, Jtr_pred = 0.647813, err = 0.320000, \u001b[31m   time: 56.746362 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.647917, err = 0.316667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 22/100, Jtr_pred = 0.643146, err = 0.313500, \u001b[31m   time: 57.175529 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.771225, err = 0.341667\n",
      "\u001b[0m\n",
      "it 23/100, Jtr_pred = 0.648578, err = 0.308500, \u001b[31m   time: 56.844762 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.782726, err = 0.375000\n",
      "\u001b[0m\n",
      "it 24/100, Jtr_pred = 0.656835, err = 0.323500, \u001b[31m   time: 56.156449 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.737035, err = 0.335000\n",
      "\u001b[0m\n",
      "it 25/100, Jtr_pred = 0.635667, err = 0.308500, \u001b[31m   time: 57.378289 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 6/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.725401, err = 0.345000\n",
      "\u001b[0m\n",
      "it 26/100, Jtr_pred = 0.649252, err = 0.308500, \u001b[31m   time: 57.552534 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.731027, err = 0.330000\n",
      "\u001b[0m\n",
      "it 27/100, Jtr_pred = 0.635685, err = 0.291500, \u001b[31m   time: 55.682762 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.722428, err = 0.323333\n",
      "\u001b[0m\n",
      "it 28/100, Jtr_pred = 0.643884, err = 0.303000, \u001b[31m   time: 55.609519 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.732919, err = 0.315000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 29/100, Jtr_pred = 0.661339, err = 0.299000, \u001b[31m   time: 58.147484 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.758725, err = 0.336667\n",
      "\u001b[0m\n",
      "it 30/100, Jtr_pred = 0.662039, err = 0.305000, \u001b[31m   time: 56.503089 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 7/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.763571, err = 0.323333\n",
      "\u001b[0m\n",
      "it 31/100, Jtr_pred = 0.653454, err = 0.293000, \u001b[31m   time: 57.103069 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.799554, err = 0.346667\n",
      "\u001b[0m\n",
      "it 32/100, Jtr_pred = 0.683286, err = 0.300500, \u001b[31m   time: 58.508783 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.878817, err = 0.335000\n",
      "\u001b[0m\n",
      "it 33/100, Jtr_pred = 0.694522, err = 0.302500, \u001b[31m   time: 55.901892 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.852320, err = 0.353333\n",
      "\u001b[0m\n",
      "it 34/100, Jtr_pred = 0.670806, err = 0.289000, \u001b[31m   time: 56.737411 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.787750, err = 0.336667\n",
      "\u001b[0m\n",
      "it 35/100, Jtr_pred = 0.669303, err = 0.292500, \u001b[31m   time: 59.120677 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 8/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.787183, err = 0.313333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 36/100, Jtr_pred = 0.666949, err = 0.282500, \u001b[31m   time: 57.198601 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.793705, err = 0.315000\n",
      "\u001b[0m\n",
      "it 37/100, Jtr_pred = 0.689644, err = 0.288500, \u001b[31m   time: 55.979723 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.783131, err = 0.345000\n",
      "\u001b[0m\n",
      "it 38/100, Jtr_pred = 0.681314, err = 0.285500, \u001b[31m   time: 58.325202 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.745935, err = 0.316667\n",
      "\u001b[0m\n",
      "it 39/100, Jtr_pred = 0.662589, err = 0.278000, \u001b[31m   time: 58.762740 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.838703, err = 0.325000\n",
      "\u001b[0m\n",
      "it 40/100, Jtr_pred = 0.684383, err = 0.274000, \u001b[31m   time: 54.767552 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 9/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.808430, err = 0.303333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 41/100, Jtr_pred = 0.673213, err = 0.283500, \u001b[31m   time: 55.643866 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.952206, err = 0.348333\n",
      "\u001b[0m\n",
      "it 42/100, Jtr_pred = 0.700419, err = 0.285500, \u001b[31m   time: 55.311630 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.909357, err = 0.346667\n",
      "\u001b[0m\n",
      "it 43/100, Jtr_pred = 0.711446, err = 0.297000, \u001b[31m   time: 54.813161 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.882072, err = 0.330000\n",
      "\u001b[0m\n",
      "it 44/100, Jtr_pred = 0.680253, err = 0.278500, \u001b[31m   time: 55.363163 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.913993, err = 0.346667\n",
      "\u001b[0m\n",
      "it 45/100, Jtr_pred = 0.665446, err = 0.277000, \u001b[31m   time: 57.216700 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 10/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.868613, err = 0.335000\n",
      "\u001b[0m\n",
      "it 46/100, Jtr_pred = 0.679206, err = 0.277500, \u001b[31m   time: 59.950276 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.875001, err = 0.310000\n",
      "\u001b[0m\n",
      "it 47/100, Jtr_pred = 0.657538, err = 0.271500, \u001b[31m   time: 59.965069 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.917939, err = 0.326667\n",
      "\u001b[0m\n",
      "it 48/100, Jtr_pred = 0.649687, err = 0.261500, \u001b[31m   time: 61.111969 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.952421, err = 0.326667\n",
      "\u001b[0m\n",
      "it 49/100, Jtr_pred = 0.657099, err = 0.258000, \u001b[31m   time: 58.918935 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.985249, err = 0.326667\n",
      "\u001b[0m\n",
      "it 50/100, Jtr_pred = 0.639579, err = 0.250500, \u001b[31m   time: 60.291256 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 11/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.980284, err = 0.311667\n",
      "\u001b[0m\n",
      "it 51/100, Jtr_pred = 0.663587, err = 0.268000, \u001b[31m   time: 58.618585 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.988519, err = 0.333333\n",
      "\u001b[0m\n",
      "it 52/100, Jtr_pred = 0.675269, err = 0.256000, \u001b[31m   time: 59.832342 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.012681, err = 0.323333\n",
      "\u001b[0m\n",
      "it 53/100, Jtr_pred = 0.667106, err = 0.259000, \u001b[31m   time: 59.893007 seconds\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    Jdev = 0.953196, err = 0.320000\n",
      "\u001b[0m\n",
      "it 54/100, Jtr_pred = 0.663361, err = 0.266000, \u001b[31m   time: 61.384748 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.020263, err = 0.328333\n",
      "\u001b[0m\n",
      "it 55/100, Jtr_pred = 0.692348, err = 0.254000, \u001b[31m   time: 75.343554 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 12/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.051866, err = 0.311667\n",
      "\u001b[0m\n",
      "it 56/100, Jtr_pred = 0.673079, err = 0.246500, \u001b[31m   time: 61.148101 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.068652, err = 0.311667\n",
      "\u001b[0m\n",
      "it 57/100, Jtr_pred = 0.698693, err = 0.251000, \u001b[31m   time: 57.160601 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.026201, err = 0.321667\n",
      "\u001b[0m\n",
      "it 58/100, Jtr_pred = 0.695969, err = 0.254500, \u001b[31m   time: 59.739826 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.108938, err = 0.310000\n",
      "\u001b[0m\n",
      "it 59/100, Jtr_pred = 0.760707, err = 0.265000, \u001b[31m   time: 58.322733 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.131035, err = 0.290000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 60/100, Jtr_pred = 0.741126, err = 0.256000, \u001b[31m   time: 59.665227 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 13/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.116799, err = 0.318333\n",
      "\u001b[0m\n",
      "it 61/100, Jtr_pred = 0.672665, err = 0.237500, \u001b[31m   time: 58.786332 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.142461, err = 0.330000\n",
      "\u001b[0m\n",
      "it 62/100, Jtr_pred = 0.636889, err = 0.234500, \u001b[31m   time: 59.959944 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.213507, err = 0.348333\n",
      "\u001b[0m\n",
      "it 63/100, Jtr_pred = 0.651334, err = 0.247500, \u001b[31m   time: 60.432082 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.127014, err = 0.321667\n",
      "\u001b[0m\n",
      "it 64/100, Jtr_pred = 0.650440, err = 0.245500, \u001b[31m   time: 58.437886 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.076019, err = 0.310000\n",
      "\u001b[0m\n",
      "it 65/100, Jtr_pred = 0.656401, err = 0.255000, \u001b[31m   time: 60.315699 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 14/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.158960, err = 0.296667\n",
      "\u001b[0m\n",
      "it 66/100, Jtr_pred = 0.630929, err = 0.249000, \u001b[31m   time: 59.600381 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.083408, err = 0.290000\n",
      "\u001b[0m\n",
      "it 67/100, Jtr_pred = 0.650904, err = 0.223500, \u001b[31m   time: 60.155704 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.219231, err = 0.298333\n",
      "\u001b[0m\n",
      "it 68/100, Jtr_pred = 0.661647, err = 0.242500, \u001b[31m   time: 60.120866 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.193192, err = 0.296667\n",
      "\u001b[0m\n",
      "it 69/100, Jtr_pred = 0.673027, err = 0.224500, \u001b[31m   time: 59.618756 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.286311, err = 0.336667\n",
      "\u001b[0m\n",
      "it 70/100, Jtr_pred = 0.626242, err = 0.228500, \u001b[31m   time: 59.572575 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 15/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.164558, err = 0.301667\n",
      "\u001b[0m\n",
      "it 71/100, Jtr_pred = 0.603760, err = 0.210500, \u001b[31m   time: 59.634602 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.313500, err = 0.321667\n",
      "\u001b[0m\n",
      "it 72/100, Jtr_pred = 0.616588, err = 0.224500, \u001b[31m   time: 59.772606 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.370443, err = 0.330000\n",
      "\u001b[0m\n",
      "it 73/100, Jtr_pred = 0.665255, err = 0.227500, \u001b[31m   time: 59.743375 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.197748, err = 0.298333\n",
      "\u001b[0m\n",
      "it 74/100, Jtr_pred = 0.641716, err = 0.221000, \u001b[31m   time: 57.012072 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.235765, err = 0.311667\n",
      "\u001b[0m\n",
      "it 75/100, Jtr_pred = 0.649815, err = 0.231500, \u001b[31m   time: 56.507493 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 16/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.322255, err = 0.323333\n",
      "\u001b[0m\n",
      "it 76/100, Jtr_pred = 0.689860, err = 0.235000, \u001b[31m   time: 61.537370 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.195339, err = 0.316667\n",
      "\u001b[0m\n",
      "it 77/100, Jtr_pred = 0.631728, err = 0.214500, \u001b[31m   time: 65.375142 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.252532, err = 0.295000\n",
      "\u001b[0m\n",
      "it 78/100, Jtr_pred = 0.672644, err = 0.219000, \u001b[31m   time: 60.176795 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.210251, err = 0.301667\n",
      "\u001b[0m\n",
      "it 79/100, Jtr_pred = 0.691887, err = 0.223000, \u001b[31m   time: 56.736103 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.337658, err = 0.318333\n",
      "\u001b[0m\n",
      "it 80/100, Jtr_pred = 0.640252, err = 0.209500, \u001b[31m   time: 56.803675 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 17/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.176813, err = 0.305000\n",
      "\u001b[0m\n",
      "it 81/100, Jtr_pred = 0.610609, err = 0.215500, \u001b[31m   time: 56.865906 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.285363, err = 0.301667\n",
      "\u001b[0m\n",
      "it 82/100, Jtr_pred = 0.618947, err = 0.214500, \u001b[31m   time: 55.226138 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.335778, err = 0.321667\n",
      "\u001b[0m\n",
      "it 83/100, Jtr_pred = 0.617148, err = 0.217500, \u001b[31m   time: 57.984195 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.275131, err = 0.308333\n",
      "\u001b[0m\n",
      "it 84/100, Jtr_pred = 0.570618, err = 0.210000, \u001b[31m   time: 58.005157 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.293139, err = 0.293333\n",
      "\u001b[0m\n",
      "it 85/100, Jtr_pred = 0.575013, err = 0.195500, \u001b[31m   time: 58.087508 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 18/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.321775, err = 0.288333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 86/100, Jtr_pred = 0.578217, err = 0.199500, \u001b[31m   time: 56.760890 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.344287, err = 0.288333\n",
      "\u001b[0m\n",
      "it 87/100, Jtr_pred = 0.596588, err = 0.204000, \u001b[31m   time: 54.637559 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.322289, err = 0.303333\n",
      "\u001b[0m\n",
      "it 88/100, Jtr_pred = 0.591331, err = 0.198500, \u001b[31m   time: 57.898323 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.401721, err = 0.305000\n",
      "\u001b[0m\n",
      "it 89/100, Jtr_pred = 0.602441, err = 0.207500, \u001b[31m   time: 56.602532 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.392051, err = 0.310000\n",
      "\u001b[0m\n",
      "it 90/100, Jtr_pred = 0.548972, err = 0.184500, \u001b[31m   time: 59.902916 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 19/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.415103, err = 0.308333\n",
      "\u001b[0m\n",
      "it 91/100, Jtr_pred = 0.606686, err = 0.208500, \u001b[31m   time: 57.366341 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.452405, err = 0.310000\n",
      "\u001b[0m\n",
      "it 92/100, Jtr_pred = 0.563584, err = 0.193000, \u001b[31m   time: 56.750146 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.540373, err = 0.336667\n",
      "\u001b[0m\n",
      "it 93/100, Jtr_pred = 0.562213, err = 0.198000, \u001b[31m   time: 56.847720 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.595945, err = 0.350000\n",
      "\u001b[0m\n",
      "it 94/100, Jtr_pred = 0.583058, err = 0.195500, \u001b[31m   time: 58.280215 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.533849, err = 0.326667\n",
      "\u001b[0m\n",
      "it 95/100, Jtr_pred = 0.576012, err = 0.198500, \u001b[31m   time: 57.320919 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 20/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.445574, err = 0.295000\n",
      "\u001b[0m\n",
      "it 96/100, Jtr_pred = 0.634172, err = 0.204000, \u001b[31m   time: 58.216353 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.532716, err = 0.325000\n",
      "\u001b[0m\n",
      "it 97/100, Jtr_pred = 0.576441, err = 0.190000, \u001b[31m   time: 56.380136 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.640170, err = 0.291667\n",
      "\u001b[0m\n",
      "it 98/100, Jtr_pred = 0.734895, err = 0.215000, \u001b[31m   time: 58.234967 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.574195, err = 0.303333\n",
      "\u001b[0m\n",
      "it 99/100, Jtr_pred = 0.568011, err = 0.192000, \u001b[31m   time: 60.566859 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.495627, err = 0.323333\n",
      "\u001b[0m\n",
      "\u001b[31m   average time: 77.904378 seconds\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "net = BNN_cat(channels_in = channels_in, side_in = image_trans_size, classes = classes, \n",
    "              N_train = NTrainPoints, lr = lr, cuda = use_cuda, grad_std_mul = grad_std_mul)\n",
    "\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# net dims\n",
    "epoch = 0\n",
    "it_count = 0\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# train\n",
    "cprint('c', '\\nTrain:')\n",
    "\n",
    "print('  init cost variables:')\n",
    "cost_train = np.zeros(nb_epochs)\n",
    "err_train = np.zeros(nb_epochs)\n",
    "cost_dev = np.zeros(nb_epochs)\n",
    "err_dev = np.zeros(nb_epochs)\n",
    "best_cost = np.inf\n",
    "best_err = np.inf\n",
    "\n",
    "tic0 = time.time()\n",
    "for i in range(epoch, nb_epochs):\n",
    "    net.set_mode_train(True)\n",
    "    tic = time.time()\n",
    "    nb_samples = 0\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        if flat_ims:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "\n",
    "        cost_pred, err = net.fit(x, y, burn_in=(i % re_burn < burn_in),\n",
    "                                 resample_momentum=(it_count % resample_its == 0),\n",
    "                                 resample_prior=(it_count % resample_prior_its == 0))\n",
    "        it_count += 1\n",
    "        err_train[i] += err\n",
    "        cost_train[i] += cost_pred\n",
    "        nb_samples += len(x)\n",
    "\n",
    "    cost_train[i] /= nb_samples\n",
    "    err_train[i] /= nb_samples\n",
    "    toc = time.time()\n",
    "\n",
    "    # ---- print\n",
    "    print(\"it %d/%d, Jtr_pred = %f, err = %f, \" % (i, nb_epochs, cost_train[i], err_train[i]), end=\"\")\n",
    "    cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "    net.update_lr(i)\n",
    "\n",
    "    # ---- save weights\n",
    "    if i % re_burn >= burn_in and i % sim_steps == 0:\n",
    "        net.save_sampled_net(max_samples=N_saves)\n",
    "    #net.save_sampled_net(max_samples=N_saves)\n",
    "    \n",
    "    if i % sim_steps == 0:\n",
    "        net.save_sampled_net(max_samples=N_saves)\n",
    "    \n",
    "    # ---- dev\n",
    "    if i % nb_its_dev == 0:\n",
    "        nb_samples = 0\n",
    "        for j, (x, y) in enumerate(valloader):\n",
    "            if flat_ims:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "\n",
    "            cost, err, probs = net.eval(x, y)\n",
    "\n",
    "            cost_dev[i] += cost\n",
    "            err_dev[i] += err\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        cost_dev[i] /= nb_samples\n",
    "        err_dev[i] /= nb_samples\n",
    "\n",
    "        cprint('g', '    Jdev = %f, err = %f\\n' % (cost_dev[i], err_dev[i]))\n",
    "        if err_dev[i] < best_err:\n",
    "            best_err = err_dev[i]\n",
    "            cprint('b', 'best test error')\n",
    "            net.save(models_dir+'/theta_best.dat')\n",
    "\n",
    "toc0 = time.time()\n",
    "runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "## SAVE WEIGHTS\n",
    "net.save_weights(models_dir + '/state_dicts.pkl')\n",
    "\n",
    "#np.save(results_dir + '/cost_train.npy', pred_cost_train)\n",
    "#np.save(results_dir + '/cost_dev.npy', cost_dev)\n",
    "np.save(results_dir + '/err_train.npy', err_train)\n",
    "np.save(results_dir + '/err_dev.npy', err_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b580a157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_object(net.weight_set_samples, models_dir+'/state_dicts.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe1763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BNN_cat at 0x217b3287580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7487d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE WEIGHTS\n",
    "#net.save_weights(models_dir + '/state_dicts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c46326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_3524/837431945.py:42: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# fig cost vs its\n",
    "\n",
    "# fig cost vs its\n",
    "textsize = 15\n",
    "marker = 5\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(0, nb_epochs, nb_its_dev), np.clip(cost_dev[::nb_its_dev], a_min=-5, a_max=5), 'b-')\n",
    "ax1.plot(np.clip(cost_train, a_min=-5, a_max=5), 'r--')\n",
    "ax1.set_ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "plt.title('classification costs')\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/cost.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_ylabel('% error')\n",
    "ax2.plot(range(0, nb_epochs, nb_its_dev), err_dev[::nb_its_dev], 'b-')\n",
    "ax2.plot(err_train, 'r--')\n",
    "ax2.set_ylim(top=1, bottom=1e-3)\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "ax2.get_yaxis().set_minor_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax2.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b874b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e38f4d",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf03314",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8174fdb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mBNN categorical output\u001b[0m\n",
      "    Total params: 21.11M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_3524/272664775.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_SGHMC_COVID150\n",
      "net 20\n",
      "\u001b[34m    Loglike = -350.909210, err = 0.246667\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", transform=transform_covid19)\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "nb_its_dev = log_interval\n",
    "flat_ims = True\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "# load data\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "net = BNN_cat(channels_in = channels_in, side_in = image_trans_size, classes = classes, \n",
    "              N_train = NTrainPoints, lr = lr, cuda = use_cuda, grad_std_mul = grad_std_mul)\n",
    "\n",
    "\n",
    "\n",
    "with open(models_dir + '/state_dicts.pkl', 'rb') as input:\n",
    "    net.weight_set_samples = pickle.load(input)\n",
    "\n",
    "net.set_mode_train(False)\n",
    "print(models_dir)\n",
    "print('net', len(net.weight_set_samples))\n",
    "test_cost = 0  # Note that these are per sample\n",
    "test_err = 0\n",
    "\n",
    "test_predictions = np.zeros((test_data_len, classes))\n",
    "\n",
    "\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "for j, (x, y) in enumerate(valloader):\n",
    "\n",
    "    cost, err, probs = net.sample_eval(x, y, Nsamples, grad=False)  # , logits=True\n",
    "    \n",
    "    test_cost += cost\n",
    "    test_err += err.cpu().numpy()\n",
    "    test_predictions[nb_samples:nb_samples + len(x), :] = probs.numpy()\n",
    "    nb_samples += len(x)\n",
    "\n",
    "# test_cost /= nb_samples\n",
    "test_err /= nb_samples\n",
    "cprint('b', '    Loglike = %5.6f, err = %1.6f\\n' % (-test_cost, test_err))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c15cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b084d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc5fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec4af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 128, 128)\n",
      "(600,)\n",
      "image number: 561\n",
      "real number: 1\n",
      "predictions [[0.3219868 0.6780132]]\n",
      "error 0\n",
      "predict 1\n",
      "561\n",
      "1\n",
      "{'0noncovid': 0, '1covid': 1}\n"
     ]
    }
   ],
   "source": [
    "x_dev = []\n",
    "y_dev = []\n",
    "for x, y in valloader:\n",
    "    x_dev.append(x.cpu().numpy())\n",
    "    y_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_dev = np.concatenate(x_dev)\n",
    "y_dev = np.concatenate(y_dev)\n",
    "print(x_dev.shape)\n",
    "print(y_dev.shape)\n",
    "\n",
    "im_ind = np.random.randint(0, y_dev.shape[0])\n",
    "# im_ind = 90\n",
    "print(\"image number:\", im_ind)\n",
    "\n",
    "x, y = x_dev[im_ind], y_dev[im_ind]\n",
    "#x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "\n",
    "print(\"real number:\", y)\n",
    "\n",
    "#plt.imshow(ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "\n",
    "ims = []\n",
    "\n",
    "# ims.append(x_rot[:, :, :])\n",
    "ims.append(x)\n",
    "\n",
    "#ims = np.concatenate(ims)\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "y = np.ones(np.shape(ims)[0])*y\n",
    "#ims = np.expand_dims(ims, axis=1)\n",
    "ims = np.array(ims)\n",
    "\n",
    "cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples,\n",
    "                                   grad=False)  # , logits=True\n",
    "\n",
    "predictions = probs.numpy()\n",
    "\n",
    "print(\"predictions\", predictions)\n",
    "\n",
    "print(\"error\", err.cpu().numpy())\n",
    "\n",
    "# predictions.max(axis=1)[0]\n",
    "# selections = (predictions[:,i] == predictions.max(axis=1))\n",
    "print(\"predict\", predictions.argmax())\n",
    "\n",
    "print(im_ind)\n",
    "\n",
    "print(valset[im_ind][1])\n",
    "\n",
    "print(valset.class_to_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16274b3",
   "metadata": {},
   "source": [
    "# predict train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "998eab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4880d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dev = []\n",
    "y_train_dev = []\n",
    "for x, y in trainloader:\n",
    "    x_train_dev.append(x.cpu().numpy())\n",
    "    y_train_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_train_dev = np.concatenate(x_train_dev)\n",
    "y_train_dev = np.concatenate(y_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b842ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "c SGHMC_predict_data\\SGHMC_train_epochs=100_lr=0.001000_batch_size=40_image_trans_size=128.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,train_data_len):\n",
    "    x, y = x_train_dev[i], y_train_dev[i]\n",
    "    \n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    #print(y)\n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, grad=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(train_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGHMC_predict_data'\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGHMC_train_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33f67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100c0ac6",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c756c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce0203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824bb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "c SGHMC_predict_data\\SGHMC_epochs=100_lr=0.001000_batch_size=40_image_trans_size=128.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,test_data_len):\n",
    "    x, y = x_dev[i], y_dev[i]\n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    \n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, grad=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(test_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGHMC_predict_data'\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGHMC_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aca5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d9c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b5572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b288b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c14025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca22f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00d3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ac71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e20c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192bd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe635022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d0363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267fcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0da06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50a7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e3695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e5d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f41c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2048e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c5013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ad175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
