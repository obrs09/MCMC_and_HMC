{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9923264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndim\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import collections\n",
    "import h5py, sys\n",
    "import gzip\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import argparse\n",
    "import matplotlib\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from numpy.random import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecda9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_resize_size = 256\n",
    "image_trans_size = 64\n",
    "batch_size = 50\n",
    "nb_epochs = 100\n",
    "\n",
    "pSGLD = False\n",
    "save_data = True\n",
    "n_samples = 90\n",
    "\n",
    "sample_freq = 2\n",
    "burn_in = 1000\n",
    "\n",
    "\n",
    "\n",
    "prior_sig = 0.1\n",
    "# Where to save models weights\n",
    "models_dir = 'models_SGHMC_COVID150'\n",
    "# Where to save plots and error, accuracy vectors\n",
    "results_dir = 'results_SGHMC_COVID150'\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model= 'Gaussian_prior'\n",
    "nsamples = int(n_samples)\n",
    "\n",
    "\n",
    "## weight saving parameters #######\n",
    "\n",
    "\n",
    "N_saves = 100\n",
    "resample_its = 50\n",
    "resample_prior_its = 15\n",
    "re_burn = 1e8\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## weight saving parameters #######\n",
    "\n",
    "sim_steps = 2\n",
    "\n",
    "###################################\n",
    "\n",
    "Nsamples = nsamples\n",
    "\n",
    "save_every = int(nb_epochs/20)  \n",
    "# We sample every 2 epochs as I have found samples to be correlated after only 1\n",
    "num_workers = 4\n",
    "nhid = 1200\n",
    "\n",
    "grad_std_mul=20\n",
    "\n",
    "transform_covid19 = transforms.Compose([\n",
    "    transforms.Resize(image_trans_size),\n",
    "    transforms.CenterCrop(image_trans_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Grayscale(num_output_channels=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b5e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d20a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not isinstance(paths, (list, tuple)):\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "\n",
    "\n",
    "def humansize(nbytes):\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes) - 1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes)\n",
    "    return '%s%s' % (f, suffixes[i])\n",
    "\n",
    "\n",
    "def get_num_batches(nb_samples, batch_size, roundup=True):\n",
    "    if roundup:\n",
    "        return ((nb_samples + (-nb_samples % batch_size)) / batch_size)  # roundup division\n",
    "    else:\n",
    "        return nb_samples / batch_size\n",
    "\n",
    "\n",
    "def generate_ind_batch(nb_samples, batch_size, random=True, roundup=True):\n",
    "    if random:\n",
    "        ind = np.random.permutation(nb_samples)\n",
    "    else:\n",
    "        ind = range(int(nb_samples))\n",
    "    for i in range(int(get_num_batches(nb_samples, batch_size, roundup))):\n",
    "        yield ind[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "\n",
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def cprint(color, text, **kwargs):\n",
    "    if color[0] == '*':\n",
    "        pre_code = '1;'\n",
    "        color = color[1:]\n",
    "    else:\n",
    "        pre_code = ''\n",
    "    code = {\n",
    "        'a': '30',\n",
    "        'r': '31',\n",
    "        'g': '32',\n",
    "        'y': '33',\n",
    "        'b': '34',\n",
    "        'p': '35',\n",
    "        'c': '36',\n",
    "        'w': '37'\n",
    "    }\n",
    "    print(\"\\x1b[%s%sm%s\\x1b[0m\" % (pre_code, code[color], text), **kwargs)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def shuffle_in_unison_scary(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "class Datafeed(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "class DatafeedImage(data.Dataset):\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.x_train[index]\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "\n",
    "\n",
    "### functions for BNN with gauss output: ###\n",
    "\n",
    "def diagonal_gauss_loglike(x, mu, sigma):\n",
    "    # note that we can just treat each dim as isotropic and then do sum\n",
    "    cte_term = -(0.5)*np.log(2*np.pi)\n",
    "    det_sig_term = -torch.log(sigma)\n",
    "    inner = (x - mu)/sigma\n",
    "    dist_term = -(0.5)*(inner**2)\n",
    "    log_px = (cte_term + det_sig_term + dist_term).sum(dim=1, keepdim=False)\n",
    "    return log_px\n",
    "\n",
    "def get_rms(mu, y, y_means, y_stds):\n",
    "    x_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    return torch.sqrt(((x_un - y_un)**2).sum() / y.shape[0])\n",
    "\n",
    "\n",
    "def get_loglike(mu, sigma, y, y_means, y_stds):\n",
    "    mu_un = mu * y_stds + y_means\n",
    "    y_un = y * y_stds + y_means\n",
    "    sigma_un = sigma * y_stds\n",
    "    ll = diagonal_gauss_loglike(y_un, mu_un, sigma_un)\n",
    "    return ll.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0584ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BaseNet(object):\n",
    "    def __init__(self):\n",
    "        cprint('c', '\\nNet:')\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return np.sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "    def set_mode_train(self, train=True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def update_lr(self, epoch, gamma=0.99):\n",
    "        self.epoch += 1\n",
    "        if self.schedule is not None:\n",
    "            if len(self.schedule) == 0 or epoch in self.schedule:\n",
    "                self.lr *= gamma\n",
    "                print('learning rate: %f  (%d)\\n' % self.lr, epoch)\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.lr\n",
    "\n",
    "    def save(self, filename):\n",
    "        cprint('c', 'Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        cprint('c', 'Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class H_SA_SGHMC(Optimizer):\n",
    "    \"\"\" Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses scale adaption during burn-in\n",
    "        procedure to find some hyperparamters. A gaussian prior is placed over parameters and a Gamma\n",
    "        Hyperprior is placed over the prior's standard deviation\"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-2, base_C=0.05, gauss_sig=0.1, alpha0=10, beta0=10):\n",
    "\n",
    "        self.eps = 1e-6\n",
    "        self.alpha0 = alpha0\n",
    "        self.beta0 = beta0\n",
    "\n",
    "        if gauss_sig == 0:\n",
    "            self.weight_decay = 0\n",
    "        else:\n",
    "            self.weight_decay = 1 / (gauss_sig ** 2)\n",
    "\n",
    "        if self.weight_decay <= 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if base_C < 0:\n",
    "            raise ValueError(\"Invalid friction term: {}\".format(base_C))\n",
    "\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            base_C=base_C,\n",
    "        )\n",
    "        super(H_SA_SGHMC, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, burn_in=False, resample_momentum=False, resample_prior=False):\n",
    "        \"\"\"Simulate discretized Hamiltonian dynamics for one step\"\"\"\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:  # iterate over blocks -> the ones defined in defaults. We dont use groups.\n",
    "            for p in group[\"params\"]:  # these are weight and bias matrices\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                state = self.state[p]  # define dict for each individual param\n",
    "                if len(state) == 0:\n",
    "                    state[\"iteration\"] = 0\n",
    "                    state[\"tau\"] = torch.ones_like(p)\n",
    "                    state[\"g\"] = torch.ones_like(p)\n",
    "                    state[\"V_hat\"] = torch.ones_like(p)\n",
    "                    state[\"v_momentum\"] = torch.zeros_like(\n",
    "                        p)  # p.data.new(p.data.size()).normal_(mean=0, std=np.sqrt(group[\"lr\"])) #\n",
    "                    state['weight_decay'] = self.weight_decay\n",
    "\n",
    "                state[\"iteration\"] += 1  # this is kind of useless now but lets keep it provisionally\n",
    "\n",
    "                if resample_prior:\n",
    "                    alpha = self.alpha0 + p.data.nelement() / 2\n",
    "                    beta = self.beta0 + (p.data ** 2).sum().item() / 2\n",
    "                    gamma_sample = gamma(shape=alpha, scale=1 / (beta), size=None)\n",
    "                    #                     print('std', 1/np.sqrt(gamma_sample))\n",
    "                    state['weight_decay'] = gamma_sample\n",
    "\n",
    "                base_C, lr = group[\"base_C\"], group[\"lr\"]\n",
    "                weight_decay = state[\"weight_decay\"]\n",
    "                tau, g, V_hat = state[\"tau\"], state[\"g\"], state[\"V_hat\"]\n",
    "\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "\n",
    "                # update parameters during burn-in\n",
    "                if burn_in:  # We update g first as it makes most sense\n",
    "                    tau.add_(-tau * (g ** 2) / (\n",
    "                                V_hat + self.eps) + 1)  # specifies the moving average window, see Eq 9 in [1] left\n",
    "                    tau_inv = 1. / (tau + self.eps)\n",
    "                    g.add_(-tau_inv * g + tau_inv * d_p)  # average gradient see Eq 9 in [1] right\n",
    "                    V_hat.add_(-tau_inv * V_hat + tau_inv * (d_p ** 2))  # gradient variance see Eq 8 in [1]\n",
    "\n",
    "                V_sqrt = torch.sqrt(V_hat)\n",
    "                V_inv_sqrt = 1. / (V_sqrt + self.eps)  # preconditioner\n",
    "\n",
    "                if resample_momentum:  # equivalent to var = M under momentum reparametrisation\n",
    "                    state[\"v_momentum\"] = torch.normal(mean=torch.zeros_like(d_p),\n",
    "                                                       std=torch.sqrt((lr ** 2) * V_inv_sqrt))\n",
    "                v_momentum = state[\"v_momentum\"]\n",
    "\n",
    "                noise_var = (2. * (lr ** 2) * V_inv_sqrt * base_C - (lr ** 4))\n",
    "                noise_std = torch.sqrt(torch.clamp(noise_var, min=1e-16))\n",
    "                # sample random epsilon\n",
    "                noise_sample = torch.normal(mean=torch.zeros_like(d_p), std=torch.ones_like(d_p) * noise_std)\n",
    "\n",
    "                # update momentum (Eq 10 right in [1])\n",
    "                v_momentum.add_(- (lr ** 2) * V_inv_sqrt * d_p - base_C * v_momentum + noise_sample)\n",
    "\n",
    "                # update theta (Eq 10 left in [1])\n",
    "                p.data.add_(v_momentum)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef19b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, width, depth, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "\n",
    "        layers = [nn.Linear(input_dim, width), nn.ReLU()]\n",
    "        for i in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BNN_cat(BaseNet):  # for categorical distributions\n",
    "    def __init__(self, channels_in=1, side_in=224, classes=2, N_train = 300, lr=1e-2, cuda=True, grad_std_mul=30):\n",
    "        super(BNN_cat, self).__init__()\n",
    "\n",
    "        cprint('y', 'BNN categorical output')\n",
    "        self.lr = lr\n",
    "        self.channels_in = channels_in\n",
    "        self.side_in = side_in\n",
    "        self.classes = classes\n",
    "        self.model = MLP(input_dim=self.channels_in * self.side_in * self.side_in, width=1200, depth=2, output_dim=self.classes)\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.N_train = N_train\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.schedule = None  # [] #[50,200,400,600]\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.grad_buff = []\n",
    "        self.max_grad = 1e20\n",
    "        self.grad_std_mul = grad_std_mul\n",
    "\n",
    "        self.weight_set_samples = []\n",
    "\n",
    "    def create_net(self):\n",
    "        torch.manual_seed(42)\n",
    "        if self.cuda:\n",
    "            torch.cuda.manual_seed(42)\n",
    "        if self.cuda:\n",
    "            self.model.cuda()\n",
    "\n",
    "        print('    Total params: %.2fM' % (self.get_nb_parameters() / 1000000.0))\n",
    "\n",
    "    def create_opt(self):\n",
    "        \"\"\"This optimiser incorporates the gaussian prior term automatically. The prior variance is gibbs sampled from\n",
    "        its posterior using a gamma hyper-prior.\"\"\"\n",
    "        self.optimizer = H_SA_SGHMC(params=self.model.parameters(), lr=self.lr, base_C=0.05, gauss_sig=0.1)  # this last parameter does nothing\n",
    "\n",
    "    def fit(self, x, y, burn_in=False, resample_momentum=False, resample_prior=False):\n",
    "        self.set_mode_train(train=True)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = F.cross_entropy(out, y, reduction='mean')\n",
    "        loss = loss * self.N_train  # We use mean because we treat as an estimation of whole dataset\n",
    "        loss.backward()\n",
    "        #print('len', len(self.grad_buff))\n",
    "        #print([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))])\n",
    "        # Gradient buffer to allow for dynamic clipping and prevent explosions\n",
    "        if len(self.grad_buff) > 1000:\n",
    "            #self.grad_buff = [self.grad_buff[i].cpu() for i in range(len(self.grad_buff))]\n",
    "            #print('len',len(self.grad_buff), self.grad_buff)\n",
    "            #print(type(self.grad_buff))\n",
    "            #print(np.array(self.grad_buff))\n",
    "\n",
    "            self.max_grad = np.mean([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))]) + self.grad_std_mul * np.std([self.grad_buff[i].cpu() for i in range(len(self.grad_buff))])\n",
    "            self.grad_buff.pop(0)\n",
    "        # Clipping to prevent explosions\n",
    "        self.grad_buff.append(nn.utils.clip_grad_norm_(parameters=self.model.parameters(),\n",
    "                                                       max_norm=self.max_grad, norm_type=2))\n",
    "        if self.grad_buff[-1] >= self.max_grad:\n",
    "            print(self.max_grad, self.grad_buff[-1])\n",
    "            self.grad_buff.pop()\n",
    "        self.optimizer.step(burn_in=burn_in, resample_momentum=resample_momentum, resample_prior=resample_prior)\n",
    "\n",
    "        # out: (batch_size, out_channels, out_caps_dims)\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data * x.shape[0] / self.N_train, err\n",
    "\n",
    "    def eval(self, x, y, train=False):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "\n",
    "        out = self.model(x)\n",
    "        loss = F.cross_entropy(out, y, reduction='sum')\n",
    "        probs = F.softmax(out, dim=1).data.cpu()\n",
    "\n",
    "        pred = out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        return loss.data, err, probs\n",
    "\n",
    "    def save_sampled_net(self, max_samples):\n",
    "\n",
    "        if len(self.weight_set_samples) >= max_samples:\n",
    "            self.weight_set_samples.pop(0)\n",
    "\n",
    "        self.weight_set_samples.append(copy.deepcopy(self.model.state_dict()))\n",
    "\n",
    "        cprint('c', ' saving weight samples %d/%d' % (len(self.weight_set_samples), max_samples))\n",
    "        return None\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.set_mode_train(train=False)\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "        out = self.model(x)\n",
    "        probs = F.softmax(out, dim=1).data.cpu()\n",
    "        return probs.data\n",
    "\n",
    "    def sample_predict(self, x, Nsamples=0, grad=False):\n",
    "        \"\"\"return predictions using multiple samples from posterior\"\"\"\n",
    "        self.set_mode_train(train=False)\n",
    "        if Nsamples == 0:\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "        x, = to_variable(var=(x, ), cuda=self.cuda)\n",
    "\n",
    "        if grad:\n",
    "            self.optimizer.zero_grad()\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out[idx] = self.model(x)\n",
    "\n",
    "        out = out[:idx]\n",
    "        prob_out = F.softmax(out, dim=2)\n",
    "\n",
    "        if grad:\n",
    "            return prob_out\n",
    "        else:\n",
    "            return prob_out.data\n",
    "\n",
    "    def sample_eval(self, x, y, Nsamples=0, grad=False):\n",
    "        #print('in sample_eval')\n",
    "        \"\"\"return predictions using multiple samples from posterior\"\"\"\n",
    "        self.set_mode_train(train=False)\n",
    "        if Nsamples == 0:\n",
    "            #print('Nsamples=0')\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "        x, y = to_variable(var=(x, y.long()), cuda=self.cuda)\n",
    "        \n",
    "        \n",
    "        if grad:\n",
    "            print('grad')\n",
    "            self.optimizer.zero_grad()\n",
    "            if not x.requires_grad:\n",
    "                x.requires_grad = True\n",
    "\n",
    "        out = x.data.new(Nsamples, x.shape[0], self.classes)\n",
    "        #print('momomomomo', len(self.weight_set_samples))\n",
    "        # iterate over all saved weight configuration samples\n",
    "        for idx, weight_dict in enumerate(self.weight_set_samples):\n",
    "\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            #print('ccccccc', self.model, x.size()[0])\n",
    "            #print('mmmmmmm', x.resize_(x.size()[0], self.side_in * self.side_in).size())\n",
    "            out[idx] = self.model(x.resize_(x.size()[0], self.side_in * self.side_in))\n",
    "\n",
    "        #print('idxxxxxxxxxx', idx)\n",
    "        out = out[:idx]\n",
    "\n",
    "        mean_out = F.softmax(out, dim=2).mean(dim=0, keepdim=False)\n",
    "\n",
    "        loss = F.cross_entropy(mean_out, y, reduction='sum')\n",
    "        prob_out = F.softmax(mean_out, dim=1).data.cpu()\n",
    "\n",
    "        pred = mean_out.data.max(dim=1, keepdim=False)[1]  # get the index of the max log-probability\n",
    "        err = pred.ne(y.data).sum()\n",
    "\n",
    "        if grad:\n",
    "            return loss.data, err, prob_out\n",
    "        else:\n",
    "            return loss.data, err, prob_out\n",
    "\n",
    "    def get_weight_samples(self, Nsamples=0):\n",
    "        \"\"\"return weight samples from posterior in a single-column array\"\"\"\n",
    "        weight_vec = []\n",
    "\n",
    "        if Nsamples == 0 or Nsamples > len(self.weight_set_samples):\n",
    "            Nsamples = len(self.weight_set_samples)\n",
    "\n",
    "        for idx, state_dict in enumerate(self.weight_set_samples):\n",
    "            if idx == Nsamples:\n",
    "                break\n",
    "\n",
    "            for key in state_dict.keys():\n",
    "                if 'weight' in key:\n",
    "                    weight_mtx = state_dict[key].cpu().data\n",
    "                    for weight in weight_mtx.view(-1):\n",
    "                        weight_vec.append(weight)\n",
    "\n",
    "        return np.array(weight_vec)\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        save_object(self.weight_set_samples, filename)\n",
    "\n",
    "    def load_weights(self, filename, subsample=1):\n",
    "        self.weight_set_samples = load_object(filename)\n",
    "        self.weight_set_samples = self.weight_set_samples[::subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5790c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f17b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80712553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", transform=transform_covid19)\n",
    "\n",
    "\n",
    "channels_in = trainset[0][0].size()[0]\n",
    "classes = np.shape(np.unique(trainset.targets))[0]\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "nb_its_dev = log_interval\n",
    "flat_ims = True\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "# load data\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba9e19a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mBNN categorical output\u001b[0m\n",
      "    Total params: 6.36M\n",
      "\u001b[36m\n",
      "Train:\u001b[0m\n",
      "  init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_23176/272664775.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n",
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_23176/1161784216.py:63: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1050.)\n",
      "  d_p.add_(weight_decay, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/100, Jtr_pred = 0.691832, err = 0.487000, \u001b[31m   time: 52.354128 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 1/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.694828, err = 0.503333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 1/100, Jtr_pred = 0.687569, err = 0.472000, \u001b[31m   time: 52.117617 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.690199, err = 0.480000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 2/100, Jtr_pred = 0.686375, err = 0.461000, \u001b[31m   time: 52.646299 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 2/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.687517, err = 0.463333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 3/100, Jtr_pred = 0.676584, err = 0.433000, \u001b[31m   time: 51.539623 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.673075, err = 0.416667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 4/100, Jtr_pred = 0.674853, err = 0.434000, \u001b[31m   time: 50.189910 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 3/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.668070, err = 0.428333\n",
      "\u001b[0m\n",
      "it 5/100, Jtr_pred = 0.676086, err = 0.419000, \u001b[31m   time: 50.887695 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.662352, err = 0.413333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 6/100, Jtr_pred = 0.677186, err = 0.414000, \u001b[31m   time: 52.219969 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 4/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.661480, err = 0.405000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 7/100, Jtr_pred = 0.674465, err = 0.420000, \u001b[31m   time: 52.131142 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.661772, err = 0.410000\n",
      "\u001b[0m\n",
      "it 8/100, Jtr_pred = 0.669510, err = 0.411500, \u001b[31m   time: 51.819943 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 5/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.675794, err = 0.440000\n",
      "\u001b[0m\n",
      "it 9/100, Jtr_pred = 0.664511, err = 0.414500, \u001b[31m   time: 52.676040 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.658492, err = 0.421667\n",
      "\u001b[0m\n",
      "it 10/100, Jtr_pred = 0.666412, err = 0.430500, \u001b[31m   time: 50.701794 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 6/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.652921, err = 0.386667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 11/100, Jtr_pred = 0.670588, err = 0.414500, \u001b[31m   time: 49.849334 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.678477, err = 0.436667\n",
      "\u001b[0m\n",
      "it 12/100, Jtr_pred = 0.666889, err = 0.412500, \u001b[31m   time: 51.602389 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 7/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.651638, err = 0.425000\n",
      "\u001b[0m\n",
      "it 13/100, Jtr_pred = 0.649587, err = 0.380500, \u001b[31m   time: 53.910226 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.644675, err = 0.383333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 14/100, Jtr_pred = 0.641973, err = 0.362000, \u001b[31m   time: 57.372739 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 8/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.637948, err = 0.395000\n",
      "\u001b[0m\n",
      "it 15/100, Jtr_pred = 0.642486, err = 0.375000, \u001b[31m   time: 58.740950 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.607575, err = 0.350000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 16/100, Jtr_pred = 0.634469, err = 0.346500, \u001b[31m   time: 57.700580 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 9/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.604806, err = 0.336667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 17/100, Jtr_pred = 0.640054, err = 0.358000, \u001b[31m   time: 57.528927 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.630634, err = 0.351667\n",
      "\u001b[0m\n",
      "it 18/100, Jtr_pred = 0.639840, err = 0.348000, \u001b[31m   time: 58.530138 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 10/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.647409, err = 0.375000\n",
      "\u001b[0m\n",
      "it 19/100, Jtr_pred = 0.640733, err = 0.355500, \u001b[31m   time: 52.843656 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.636671, err = 0.350000\n",
      "\u001b[0m\n",
      "it 20/100, Jtr_pred = 0.636716, err = 0.344500, \u001b[31m   time: 57.056900 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 11/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.612170, err = 0.328333\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 21/100, Jtr_pred = 0.630631, err = 0.340000, \u001b[31m   time: 58.268660 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.615324, err = 0.345000\n",
      "\u001b[0m\n",
      "it 22/100, Jtr_pred = 0.646315, err = 0.356000, \u001b[31m   time: 56.642897 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 12/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.620859, err = 0.331667\n",
      "\u001b[0m\n",
      "it 23/100, Jtr_pred = 0.646310, err = 0.356500, \u001b[31m   time: 60.151415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.635014, err = 0.331667\n",
      "\u001b[0m\n",
      "it 24/100, Jtr_pred = 0.642050, err = 0.352500, \u001b[31m   time: 60.128770 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 13/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.620578, err = 0.338333\n",
      "\u001b[0m\n",
      "it 25/100, Jtr_pred = 0.623718, err = 0.334000, \u001b[31m   time: 60.581974 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.660629, err = 0.361667\n",
      "\u001b[0m\n",
      "it 26/100, Jtr_pred = 0.652541, err = 0.364000, \u001b[31m   time: 55.980761 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 14/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.685832, err = 0.383333\n",
      "\u001b[0m\n",
      "it 27/100, Jtr_pred = 0.641557, err = 0.349500, \u001b[31m   time: 60.437299 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.641461, err = 0.336667\n",
      "\u001b[0m\n",
      "it 28/100, Jtr_pred = 0.632843, err = 0.338000, \u001b[31m   time: 59.480597 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 15/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.624327, err = 0.316667\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 29/100, Jtr_pred = 0.637442, err = 0.331000, \u001b[31m   time: 60.808340 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.636219, err = 0.316667\n",
      "\u001b[0m\n",
      "it 30/100, Jtr_pred = 0.624203, err = 0.329500, \u001b[31m   time: 60.340639 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 16/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.660557, err = 0.351667\n",
      "\u001b[0m\n",
      "it 31/100, Jtr_pred = 0.611362, err = 0.317000, \u001b[31m   time: 59.986381 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622638, err = 0.325000\n",
      "\u001b[0m\n",
      "it 32/100, Jtr_pred = 0.622848, err = 0.331000, \u001b[31m   time: 61.769180 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 17/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.621362, err = 0.295000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 33/100, Jtr_pred = 0.608896, err = 0.314000, \u001b[31m   time: 60.951703 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.602845, err = 0.285000\n",
      "\u001b[0m\n",
      "\u001b[34mbest test error\u001b[0m\n",
      "\u001b[36mWritting models_SGHMC_COVID150/theta_best.dat\n",
      "\u001b[0m\n",
      "it 34/100, Jtr_pred = 0.600410, err = 0.305000, \u001b[31m   time: 59.193501 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 18/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.622065, err = 0.296667\n",
      "\u001b[0m\n",
      "it 35/100, Jtr_pred = 0.621003, err = 0.315000, \u001b[31m   time: 59.427563 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.643515, err = 0.308333\n",
      "\u001b[0m\n",
      "it 36/100, Jtr_pred = 0.622575, err = 0.312000, \u001b[31m   time: 61.841874 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 19/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.609621, err = 0.285000\n",
      "\u001b[0m\n",
      "it 37/100, Jtr_pred = 0.634715, err = 0.322000, \u001b[31m   time: 60.577197 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.625546, err = 0.296667\n",
      "\u001b[0m\n",
      "it 38/100, Jtr_pred = 0.642720, err = 0.323500, \u001b[31m   time: 60.374700 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 20/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.669133, err = 0.313333\n",
      "\u001b[0m\n",
      "it 39/100, Jtr_pred = 0.645944, err = 0.316000, \u001b[31m   time: 61.366965 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.728992, err = 0.358333\n",
      "\u001b[0m\n",
      "it 40/100, Jtr_pred = 0.644125, err = 0.317000, \u001b[31m   time: 60.767917 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 21/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.727435, err = 0.335000\n",
      "\u001b[0m\n",
      "it 41/100, Jtr_pred = 0.630885, err = 0.308500, \u001b[31m   time: 62.110568 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.751109, err = 0.331667\n",
      "\u001b[0m\n",
      "it 42/100, Jtr_pred = 0.645852, err = 0.315500, \u001b[31m   time: 61.769819 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 22/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.771615, err = 0.335000\n",
      "\u001b[0m\n",
      "it 43/100, Jtr_pred = 0.655326, err = 0.312000, \u001b[31m   time: 60.488800 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.769050, err = 0.335000\n",
      "\u001b[0m\n",
      "it 44/100, Jtr_pred = 0.649381, err = 0.305500, \u001b[31m   time: 71.079535 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 23/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.730346, err = 0.340000\n",
      "\u001b[0m\n",
      "it 45/100, Jtr_pred = 0.649853, err = 0.311000, \u001b[31m   time: 59.701838 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.709357, err = 0.341667\n",
      "\u001b[0m\n",
      "it 46/100, Jtr_pred = 0.645704, err = 0.306000, \u001b[31m   time: 61.468569 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 24/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.696972, err = 0.343333\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 47/100, Jtr_pred = 0.654931, err = 0.320500, \u001b[31m   time: 58.598020 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.722181, err = 0.360000\n",
      "\u001b[0m\n",
      "it 48/100, Jtr_pred = 0.671424, err = 0.331000, \u001b[31m   time: 59.100794 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 25/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.749764, err = 0.365000\n",
      "\u001b[0m\n",
      "it 49/100, Jtr_pred = 0.681969, err = 0.331500, \u001b[31m   time: 59.373184 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.789062, err = 0.351667\n",
      "\u001b[0m\n",
      "it 50/100, Jtr_pred = 0.652165, err = 0.308000, \u001b[31m   time: 55.858081 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 26/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.792016, err = 0.361667\n",
      "\u001b[0m\n",
      "it 51/100, Jtr_pred = 0.630893, err = 0.297500, \u001b[31m   time: 51.200441 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.777868, err = 0.363333\n",
      "\u001b[0m\n",
      "it 52/100, Jtr_pred = 0.645445, err = 0.302000, \u001b[31m   time: 53.526391 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 27/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.817439, err = 0.378333\n",
      "\u001b[0m\n",
      "it 53/100, Jtr_pred = 0.658088, err = 0.309500, \u001b[31m   time: 52.570415 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.786590, err = 0.378333\n",
      "\u001b[0m\n",
      "it 54/100, Jtr_pred = 0.657376, err = 0.321500, \u001b[31m   time: 53.383836 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 28/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.767035, err = 0.340000\n",
      "\u001b[0m\n",
      "it 55/100, Jtr_pred = 0.638914, err = 0.311000, \u001b[31m   time: 52.885012 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.798789, err = 0.353333\n",
      "\u001b[0m\n",
      "it 56/100, Jtr_pred = 0.647002, err = 0.301000, \u001b[31m   time: 51.710909 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 29/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.812909, err = 0.363333\n",
      "\u001b[0m\n",
      "it 57/100, Jtr_pred = 0.637577, err = 0.299000, \u001b[31m   time: 53.355072 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.813671, err = 0.341667\n",
      "\u001b[0m\n",
      "it 58/100, Jtr_pred = 0.647909, err = 0.303500, \u001b[31m   time: 52.210965 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 30/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.835911, err = 0.361667\n",
      "\u001b[0m\n",
      "it 59/100, Jtr_pred = 0.637845, err = 0.285500, \u001b[31m   time: 52.966008 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.858826, err = 0.330000\n",
      "\u001b[0m\n",
      "it 60/100, Jtr_pred = 0.616513, err = 0.289000, \u001b[31m   time: 52.083737 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 31/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.848423, err = 0.353333\n",
      "\u001b[0m\n",
      "it 61/100, Jtr_pred = 0.629094, err = 0.286000, \u001b[31m   time: 52.159561 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.818517, err = 0.326667\n",
      "\u001b[0m\n",
      "it 62/100, Jtr_pred = 0.643979, err = 0.281500, \u001b[31m   time: 52.192001 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 32/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.856413, err = 0.338333\n",
      "\u001b[0m\n",
      "it 63/100, Jtr_pred = 0.647683, err = 0.294000, \u001b[31m   time: 53.075747 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.821944, err = 0.340000\n",
      "\u001b[0m\n",
      "it 64/100, Jtr_pred = 0.646049, err = 0.301000, \u001b[31m   time: 52.020564 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 33/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.801141, err = 0.311667\n",
      "\u001b[0m\n",
      "it 65/100, Jtr_pred = 0.632139, err = 0.285500, \u001b[31m   time: 51.151769 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.850870, err = 0.328333\n",
      "\u001b[0m\n",
      "it 66/100, Jtr_pred = 0.623519, err = 0.278500, \u001b[31m   time: 51.958377 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 34/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.791941, err = 0.310000\n",
      "\u001b[0m\n",
      "it 67/100, Jtr_pred = 0.641390, err = 0.288000, \u001b[31m   time: 51.506088 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.796001, err = 0.288333\n",
      "\u001b[0m\n",
      "it 68/100, Jtr_pred = 0.636264, err = 0.280000, \u001b[31m   time: 53.232057 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 35/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.801021, err = 0.306667\n",
      "\u001b[0m\n",
      "it 69/100, Jtr_pred = 0.620044, err = 0.267500, \u001b[31m   time: 50.593303 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.816668, err = 0.310000\n",
      "\u001b[0m\n",
      "it 70/100, Jtr_pred = 0.631700, err = 0.266000, \u001b[31m   time: 50.590652 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 36/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.807770, err = 0.306667\n",
      "\u001b[0m\n",
      "it 71/100, Jtr_pred = 0.632323, err = 0.265000, \u001b[31m   time: 51.708313 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.851709, err = 0.323333\n",
      "\u001b[0m\n",
      "it 72/100, Jtr_pred = 0.648668, err = 0.284000, \u001b[31m   time: 51.192554 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 37/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.892054, err = 0.313333\n",
      "\u001b[0m\n",
      "it 73/100, Jtr_pred = 0.625561, err = 0.265000, \u001b[31m   time: 52.816118 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.850092, err = 0.303333\n",
      "\u001b[0m\n",
      "it 74/100, Jtr_pred = 0.609971, err = 0.257500, \u001b[31m   time: 50.589936 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 38/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.859992, err = 0.310000\n",
      "\u001b[0m\n",
      "it 75/100, Jtr_pred = 0.607630, err = 0.263500, \u001b[31m   time: 51.272271 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.822308, err = 0.326667\n",
      "\u001b[0m\n",
      "it 76/100, Jtr_pred = 0.598504, err = 0.259500, \u001b[31m   time: 51.923639 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 39/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.799227, err = 0.313333\n",
      "\u001b[0m\n",
      "it 77/100, Jtr_pred = 0.606854, err = 0.260000, \u001b[31m   time: 51.517772 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.780421, err = 0.303333\n",
      "\u001b[0m\n",
      "it 78/100, Jtr_pred = 0.618283, err = 0.269000, \u001b[31m   time: 52.581043 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 40/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.767733, err = 0.301667\n",
      "\u001b[0m\n",
      "it 79/100, Jtr_pred = 0.624362, err = 0.262500, \u001b[31m   time: 52.201305 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.838982, err = 0.330000\n",
      "\u001b[0m\n",
      "it 80/100, Jtr_pred = 0.645112, err = 0.259000, \u001b[31m   time: 52.612927 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 41/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.830829, err = 0.318333\n",
      "\u001b[0m\n",
      "it 81/100, Jtr_pred = 0.632884, err = 0.258500, \u001b[31m   time: 53.223344 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.821859, err = 0.321667\n",
      "\u001b[0m\n",
      "it 82/100, Jtr_pred = 0.615466, err = 0.250500, \u001b[31m   time: 52.624021 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 42/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.821868, err = 0.315000\n",
      "\u001b[0m\n",
      "it 83/100, Jtr_pred = 0.595113, err = 0.244500, \u001b[31m   time: 59.264083 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.796137, err = 0.321667\n",
      "\u001b[0m\n",
      "it 84/100, Jtr_pred = 0.622977, err = 0.250000, \u001b[31m   time: 60.279803 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 43/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.846892, err = 0.305000\n",
      "\u001b[0m\n",
      "it 85/100, Jtr_pred = 0.626593, err = 0.253000, \u001b[31m   time: 61.571940 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.903018, err = 0.328333\n",
      "\u001b[0m\n",
      "it 86/100, Jtr_pred = 0.604062, err = 0.258000, \u001b[31m   time: 60.988235 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 44/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.834276, err = 0.301667\n",
      "\u001b[0m\n",
      "it 87/100, Jtr_pred = 0.608260, err = 0.259000, \u001b[31m   time: 61.657159 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.891980, err = 0.306667\n",
      "\u001b[0m\n",
      "it 88/100, Jtr_pred = 0.624493, err = 0.258500, \u001b[31m   time: 62.356205 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 45/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.854852, err = 0.310000\n",
      "\u001b[0m\n",
      "it 89/100, Jtr_pred = 0.595951, err = 0.257000, \u001b[31m   time: 62.501176 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.889218, err = 0.310000\n",
      "\u001b[0m\n",
      "it 90/100, Jtr_pred = 0.594125, err = 0.257000, \u001b[31m   time: 62.045322 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 46/100\u001b[0m\n",
      "\u001b[32m    Jdev = 0.877274, err = 0.298333\n",
      "\u001b[0m\n",
      "it 91/100, Jtr_pred = 0.600249, err = 0.255000, \u001b[31m   time: 62.764697 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.977964, err = 0.321667\n",
      "\u001b[0m\n",
      "it 92/100, Jtr_pred = 0.591098, err = 0.251000, \u001b[31m   time: 63.964747 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 47/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.039306, err = 0.333333\n",
      "\u001b[0m\n",
      "it 93/100, Jtr_pred = 0.623204, err = 0.246000, \u001b[31m   time: 61.254694 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.145386, err = 0.346667\n",
      "\u001b[0m\n",
      "it 94/100, Jtr_pred = 0.643611, err = 0.261500, \u001b[31m   time: 62.573912 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 48/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.102452, err = 0.340000\n",
      "\u001b[0m\n",
      "it 95/100, Jtr_pred = 0.637765, err = 0.259000, \u001b[31m   time: 61.595218 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.023260, err = 0.315000\n",
      "\u001b[0m\n",
      "it 96/100, Jtr_pred = 0.623402, err = 0.266000, \u001b[31m   time: 62.760736 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 49/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.018389, err = 0.321667\n",
      "\u001b[0m\n",
      "it 97/100, Jtr_pred = 0.610334, err = 0.249000, \u001b[31m   time: 62.872684 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 1.030655, err = 0.321667\n",
      "\u001b[0m\n",
      "it 98/100, Jtr_pred = 0.614320, err = 0.256000, \u001b[31m   time: 64.321836 seconds\n",
      "\u001b[0m\n",
      "\u001b[36m saving weight samples 50/100\u001b[0m\n",
      "\u001b[32m    Jdev = 1.077846, err = 0.326667\n",
      "\u001b[0m\n",
      "it 99/100, Jtr_pred = 0.617403, err = 0.244500, \u001b[31m   time: 63.109809 seconds\n",
      "\u001b[0m\n",
      "\u001b[32m    Jdev = 0.989228, err = 0.296667\n",
      "\u001b[0m\n",
      "\u001b[31m   average time: 74.048348 seconds\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "net = BNN_cat(channels_in = channels_in, side_in = image_trans_size, classes = classes, \n",
    "              N_train = NTrainPoints, lr = lr, cuda = use_cuda, grad_std_mul = grad_std_mul)\n",
    "\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# net dims\n",
    "epoch = 0\n",
    "it_count = 0\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# train\n",
    "cprint('c', '\\nTrain:')\n",
    "\n",
    "print('  init cost variables:')\n",
    "cost_train = np.zeros(nb_epochs)\n",
    "err_train = np.zeros(nb_epochs)\n",
    "cost_dev = np.zeros(nb_epochs)\n",
    "err_dev = np.zeros(nb_epochs)\n",
    "best_cost = np.inf\n",
    "best_err = np.inf\n",
    "\n",
    "tic0 = time.time()\n",
    "for i in range(epoch, nb_epochs):\n",
    "    net.set_mode_train(True)\n",
    "    tic = time.time()\n",
    "    nb_samples = 0\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        if flat_ims:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "\n",
    "        cost_pred, err = net.fit(x, y, burn_in=(i % re_burn < burn_in),\n",
    "                                 resample_momentum=(it_count % resample_its == 0),\n",
    "                                 resample_prior=(it_count % resample_prior_its == 0))\n",
    "        it_count += 1\n",
    "        err_train[i] += err\n",
    "        cost_train[i] += cost_pred\n",
    "        nb_samples += len(x)\n",
    "\n",
    "    cost_train[i] /= nb_samples\n",
    "    err_train[i] /= nb_samples\n",
    "    toc = time.time()\n",
    "\n",
    "    # ---- print\n",
    "    print(\"it %d/%d, Jtr_pred = %f, err = %f, \" % (i, nb_epochs, cost_train[i], err_train[i]), end=\"\")\n",
    "    cprint('r', '   time: %f seconds\\n' % (toc - tic))\n",
    "    net.update_lr(i)\n",
    "\n",
    "    # ---- save weights\n",
    "    if i % re_burn >= burn_in and i % sim_steps == 0:\n",
    "        net.save_sampled_net(max_samples=N_saves)\n",
    "    #net.save_sampled_net(max_samples=N_saves)\n",
    "    \n",
    "    if i % sim_steps == 0:\n",
    "        net.save_sampled_net(max_samples=N_saves)\n",
    "    \n",
    "    # ---- dev\n",
    "    if i % nb_its_dev == 0:\n",
    "        nb_samples = 0\n",
    "        for j, (x, y) in enumerate(valloader):\n",
    "            if flat_ims:\n",
    "                x = x.view(x.shape[0], -1)\n",
    "\n",
    "            cost, err, probs = net.eval(x, y)\n",
    "\n",
    "            cost_dev[i] += cost\n",
    "            err_dev[i] += err\n",
    "            nb_samples += len(x)\n",
    "\n",
    "        cost_dev[i] /= nb_samples\n",
    "        err_dev[i] /= nb_samples\n",
    "\n",
    "        cprint('g', '    Jdev = %f, err = %f\\n' % (cost_dev[i], err_dev[i]))\n",
    "        if err_dev[i] < best_err:\n",
    "            best_err = err_dev[i]\n",
    "            cprint('b', 'best test error')\n",
    "            net.save(models_dir+'/theta_best.dat')\n",
    "\n",
    "toc0 = time.time()\n",
    "runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n",
    "cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n",
    "\n",
    "## SAVE WEIGHTS\n",
    "net.save_weights(models_dir + '/state_dicts.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b580a157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_object(net.weight_set_samples, models_dir+'/state_dicts.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe1763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BNN_cat at 0x277cb911280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7487d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE WEIGHTS\n",
    "#net.save_weights(models_dir + '/state_dicts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c46326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_23176/837431945.py:42: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"box_inches\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# fig cost vs its\n",
    "\n",
    "# fig cost vs its\n",
    "textsize = 15\n",
    "marker = 5\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(0, nb_epochs, nb_its_dev), np.clip(cost_dev[::nb_its_dev], a_min=-5, a_max=5), 'b-')\n",
    "ax1.plot(np.clip(cost_train, a_min=-5, a_max=5), 'r--')\n",
    "ax1.set_ylabel('Cross Entropy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "plt.title('classification costs')\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/cost.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_ylabel('% error')\n",
    "ax2.plot(range(0, nb_epochs, nb_its_dev), err_dev[::nb_its_dev], 'b-')\n",
    "ax2.plot(err_train, 'r--')\n",
    "ax2.set_ylim(top=1, bottom=1e-3)\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(b=True, which='major', color='k', linestyle='-')\n",
    "plt.grid(b=True, which='minor', color='k', linestyle='--')\n",
    "ax2.get_yaxis().set_minor_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax2.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "lgd = plt.legend(['test error', 'train error'], markerscale=marker, prop={'size': textsize, 'weight': 'normal'})\n",
    "ax = plt.gca()\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(textsize)\n",
    "    item.set_weight('normal')\n",
    "plt.savefig(results_dir + '/err.png', bbox_extra_artists=(lgd,), box_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b874b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31e38f4d",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf03314",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8174fdb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Data:\u001b[0m\n",
      "\u001b[36m\n",
      "Network:\u001b[0m\n",
      "\u001b[36m\n",
      "Net:\u001b[0m\n",
      "\u001b[33mBNN categorical output\u001b[0m\n",
      "    Total params: 6.36M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUAIZ~1\\AppData\\Local\\Temp/ipykernel_23176/272664775.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  return np.sum(p.numel() for p in self.model.parameters())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_SGHMC_COVID150\n",
      "net 50\n",
      "\u001b[34m    Loglike = -362.882782, err = 0.265000\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/train\", transform=transform_covid19)\n",
    "valset = torchvision.datasets.ImageFolder(root=\"./notebooks/data/COVID/test\", transform=transform_covid19)\n",
    "\n",
    "train_data_len = len(trainset.targets)\n",
    "test_data_len = len(valset.targets)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "NTrainPoints = train_data_len\n",
    "\n",
    "\n",
    "\n",
    "mkdir(models_dir)\n",
    "mkdir(results_dir)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# train config\n",
    "\n",
    "log_interval = 1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "nb_its_dev = log_interval\n",
    "flat_ims = True\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# dataset\n",
    "cprint('c', '\\nData:')\n",
    "\n",
    "# load data\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=True,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=False,\n",
    "                                              num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, pin_memory=False,\n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "## ---------------------------------------------------------------------------------------------------------------------\n",
    "# net dims\n",
    "cprint('c', '\\nNetwork:')\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "net = BNN_cat(channels_in = channels_in, side_in = image_trans_size, classes = classes, \n",
    "              N_train = NTrainPoints, lr = lr, cuda = use_cuda, grad_std_mul = grad_std_mul)\n",
    "\n",
    "\n",
    "\n",
    "with open(models_dir + '/state_dicts.pkl', 'rb') as input:\n",
    "    net.weight_set_samples = pickle.load(input)\n",
    "\n",
    "net.set_mode_train(False)\n",
    "print(models_dir)\n",
    "print('net', len(net.weight_set_samples))\n",
    "test_cost = 0  # Note that these are per sample\n",
    "test_err = 0\n",
    "\n",
    "test_predictions = np.zeros((test_data_len, classes))\n",
    "\n",
    "\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "for j, (x, y) in enumerate(valloader):\n",
    "\n",
    "    cost, err, probs = net.sample_eval(x, y, Nsamples, grad=False)  # , logits=True\n",
    "    \n",
    "    test_cost += cost\n",
    "    test_err += err.cpu().numpy()\n",
    "    test_predictions[nb_samples:nb_samples + len(x), :] = probs.numpy()\n",
    "    nb_samples += len(x)\n",
    "\n",
    "# test_cost /= nb_samples\n",
    "test_err /= nb_samples\n",
    "cprint('b', '    Loglike = %5.6f, err = %1.6f\\n' % (-test_cost, test_err))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c15cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b084d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc5fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec4af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 64, 64)\n",
      "(600,)\n",
      "image number: 375\n",
      "real number: 1\n",
      "predictions [[0.44654223 0.5534578 ]]\n",
      "error 0\n",
      "predict 1\n",
      "375\n",
      "1\n",
      "{'0noncovid': 0, '1covid': 1}\n"
     ]
    }
   ],
   "source": [
    "x_dev = []\n",
    "y_dev = []\n",
    "for x, y in valloader:\n",
    "    x_dev.append(x.cpu().numpy())\n",
    "    y_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_dev = np.concatenate(x_dev)\n",
    "y_dev = np.concatenate(y_dev)\n",
    "print(x_dev.shape)\n",
    "print(y_dev.shape)\n",
    "\n",
    "im_ind = np.random.randint(0, y_dev.shape[0])\n",
    "# im_ind = 90\n",
    "print(\"image number:\", im_ind)\n",
    "\n",
    "x, y = x_dev[im_ind], y_dev[im_ind]\n",
    "#x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "\n",
    "print(\"real number:\", y)\n",
    "\n",
    "#plt.imshow(ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "\n",
    "ims = []\n",
    "\n",
    "# ims.append(x_rot[:, :, :])\n",
    "ims.append(x)\n",
    "\n",
    "#ims = np.concatenate(ims)\n",
    "\n",
    "net.set_mode_train(False)\n",
    "\n",
    "y = np.ones(np.shape(ims)[0])*y\n",
    "#ims = np.expand_dims(ims, axis=1)\n",
    "ims = np.array(ims)\n",
    "\n",
    "cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples,\n",
    "                                   grad=False)  # , logits=True\n",
    "\n",
    "predictions = probs.numpy()\n",
    "\n",
    "print(\"predictions\", predictions)\n",
    "\n",
    "print(\"error\", err.cpu().numpy())\n",
    "\n",
    "# predictions.max(axis=1)[0]\n",
    "# selections = (predictions[:,i] == predictions.max(axis=1))\n",
    "print(\"predict\", predictions.argmax())\n",
    "\n",
    "print(im_ind)\n",
    "\n",
    "print(valset[im_ind][1])\n",
    "\n",
    "print(valset.class_to_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16274b3",
   "metadata": {},
   "source": [
    "# predict train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "998eab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4880d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dev = []\n",
    "y_train_dev = []\n",
    "for x, y in trainloader:\n",
    "    x_train_dev.append(x.cpu().numpy())\n",
    "    y_train_dev.append(y.cpu().numpy())\n",
    "\n",
    "x_train_dev = np.concatenate(x_train_dev)\n",
    "y_train_dev = np.concatenate(y_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b842ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "c SGHMC_predict_data\\SGHMC_train_epochs=100_lr=0.001000_batch_size=50_image_trans_size=64.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,train_data_len):\n",
    "    x, y = x_train_dev[i], y_train_dev[i]\n",
    "    \n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    #print(y)\n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, grad=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(train_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGHMC_predict_data'\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGHMC_train_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33f67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100c0ac6",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c756c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce0203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824bb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "c SGHMC_predict_data\\SGHMC_epochs=100_lr=0.001000_batch_size=50_image_trans_size=64.csv\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "prob = []\n",
    "for i in range(0,test_data_len):\n",
    "    x, y = x_dev[i], y_dev[i]\n",
    "    #x_rot = np.expand_dims(ndim.interpolation.rotate(x[0, :, :], 0, reshape=False, cval=-0.42421296), 0)\n",
    "    #print(\"real number:\",y)\n",
    "    y_true.append(y)\n",
    "    #plt.imshow( ndim.interpolation.rotate(x_dev[im_ind,0,:,:], 0, reshape=False))\n",
    "    #plt.show()\n",
    "    ims=[]\n",
    "    #ims.append(x_rot[:,:,:])\n",
    "    ims.append(x)\n",
    "    #ims = np.concatenate(ims)\n",
    "    net.set_mode_train(False)\n",
    "    #y = np.ones(ims.shape[0])*y\n",
    "    y = np.ones(np.shape(ims)[0])*y\n",
    "    \n",
    "    ims = np.array(ims)\n",
    "    #ims = np.expand_dims(ims, axis=1)\n",
    "    cost, err, probs = net.sample_eval(torch.from_numpy(ims), torch.from_numpy(y), Nsamples=Nsamples, grad=False) # , logits=True\n",
    "    predictions = probs.numpy()\n",
    "    prob.append(predictions)\n",
    "#     print(\"predictions\", predictions)\n",
    "#     print(\"error\", err.cpu().numpy())\n",
    "    y_pred.append(predictions.argmax())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "prob = np.array(prob)\n",
    "prob = prob.reshape(test_data_len, classes)\n",
    "\n",
    "if save_data == True:\n",
    "    save_path = 'SGHMC_predict_data'\n",
    "    mkdir(save_path)\n",
    "    file_name = \"SGHMC_epochs=%d_lr=%f_batch_size=%d_image_trans_size=%d.csv\" \\\n",
    "                % (nb_epochs, lr, batch_size, image_trans_size)\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    print('c', completeName)\n",
    "    if os.path.exists(completeName):\n",
    "        os.remove(completeName)\n",
    "    # df = pd.DataFrame(prob)\n",
    "    # df.to_csv(completeName)\n",
    "    np.savetxt(completeName, prob, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aca5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d9c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b5572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b288b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c14025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca22f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00d3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ac71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e20c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192bd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe635022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d0363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267fcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0da06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50a7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e3695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e5d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f41c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2048e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c5013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ad175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
